{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Thesis - Quintine Sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parselmouth\n",
    "import random\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import whisper\n",
    "import re\n",
    "import warnings\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 12}) # Set default font size for plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intake Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the intake questionnaires\n",
    "questionnaire_intake = pd.read_csv(\"./data/Intake_session/cleaned_curated_Intake_Session.csv\")\n",
    "questionnaire_intake.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the conversation questionnaires\n",
    "questionnaires_conv = pd.read_csv(\"./data/Conversation/Evaluation_Questionnaires/cleaned_curated_conv_coord_data_combined_ffinal.csv\")\n",
    "print(\"Conversation questionnaires:\", questionnaires_conv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaboration Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the collaboration questionnaires\n",
    "questionnaires_coll = pd.read_csv(\"./data/Collaboration/Evaluation_Questionnaires/cleaned_curated_imp_coll_coord_data_combined_ffinal.csv\")\n",
    "print(\"Collaboration questionnaires:\", questionnaires_coll.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter: Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of batch numbers\n",
    "batches = set(range(1, 68))\n",
    "\n",
    "# Set of missing batch numbers (in collaboration setting)\n",
    "missing_batches = {1, 2, 3, 4, 5, 7, 26, 34, 36, 44, 50, 51, 52, 62}\n",
    "\n",
    "# Set of available batch numbers\n",
    "available_batches = list(batches - missing_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly select 30 batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_batches = 30 # Number of batches to select \n",
    "\n",
    "# Seed random number generator\n",
    "random.seed(42)\n",
    "\n",
    "# Randomly select no_batches from the set of available batches and sort them\n",
    "selected_batches_numbers = sorted(random.sample(available_batches, no_batches))\n",
    "\n",
    "print(selected_batches_numbers) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert numbers to strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert batch numbers to strings\n",
    "selected_batches = [\"Batch_\" + str(batch) for batch in selected_batches_numbers]\n",
    "\n",
    "# Print (sorted) selected batches\n",
    "print(selected_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter questionnaire data based on Batch ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter conversation questionnaires\n",
    "filtered_questionnaires_conv = questionnaires_conv[questionnaires_conv[\"batchID\"].isin(selected_batches)]\n",
    "print(\"Conversation questionnaires filtered:\", filtered_questionnaires_conv.shape)\n",
    "\n",
    "# Filter collaboration questionnaires\n",
    "filtered_questionnaires_coll = questionnaires_coll[questionnaires_coll[\"batchID\"].isin(selected_batches)]\n",
    "print(\"Collaboration questionnaires filtered:\", filtered_questionnaires_coll.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter: Dyads with Both Participants Evaluating Both Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_dyadID(df):\n",
    "    \"\"\"\n",
    "    Get unique dyadIDs where both participants have evaluated each other.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): The dataframe containing the (conv or coll) questionnaire data.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list containing unique dyadIDs where both participants have evaluated each other.\n",
    "    \"\"\"\n",
    "    # Get unique triplets of selfPID, otherPID, and dyadID occurring in the dataframe\n",
    "    unique_triplets = set(zip(df[\"selfPID\"], df[\"otherPID\"], df[\"dyadID\"]))\n",
    "\n",
    "    # Check if the evaluations are reciprocal for each dyad\n",
    "    reciprocal_dyads = [dyadID for (selfPID, otherPID, dyadID) in unique_triplets if (otherPID, selfPID, dyadID) in unique_triplets]\n",
    "    \n",
    "    # Remove duplicates\n",
    "    reciprocal_dyads = set(reciprocal_dyads)\n",
    "    \n",
    "    return reciprocal_dyads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique dyadIDs where both participants have evaluated each other in both settings\n",
    "reciprocal_dyads = reciprocal_dyadID(filtered_questionnaires_conv) & reciprocal_dyadID(filtered_questionnaires_coll)\n",
    "\n",
    "# Only contain rows with reciprocal dyadIDs\n",
    "filtered_reciprocal_conv = filtered_questionnaires_conv[filtered_questionnaires_conv[\"dyadID\"].isin(reciprocal_dyads)]\n",
    "filtered_reciprocal_coll = filtered_questionnaires_coll[filtered_questionnaires_coll[\"dyadID\"].isin(reciprocal_dyads)]\n",
    "\n",
    "# Print the number of rows in the filtered dataframes\n",
    "print(\"Conversation questionnaires filtered on reciprocity:\", filtered_reciprocal_conv.shape)\n",
    "print(\"Collaboration questionnaires filtered on reciprocity:\", filtered_reciprocal_coll.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter: Dyads with Available Recordings (at least 2 minutes) for Both Participants in Both Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find available recording (at least 2 minutes) for each participant in each dyad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_file(recording_file, setting, batch_id):\n",
    "    \"\"\"\n",
    "    Check if the specified recording file is available in the data folder.\n",
    "    \n",
    "    Args:\n",
    "    - recording_file (str): The name of the recording file.\n",
    "    - setting (str): The setting of the recording file (i.e., \"conv\" or \"coll\").\n",
    "    - batch_id (str): The batchID value of the recording file (e.g. \"Batch_8\").\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if the file is available, False otherwise.\n",
    "    \"\"\"\n",
    "    # Define the file path based on batch_id and setting\n",
    "    if setting == \"conv\":\n",
    "        file_path = f\"data/Conversation/WAV_recordings/{batch_id}/{recording_file}.wav\"\n",
    "    elif setting == \"coll\":\n",
    "        file_path = f\"data/Collaboration/WAV_recordings/{batch_id}/{recording_file}.wav\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid setting. Please specify 'conv' or 'coll'.\")\n",
    "\n",
    "    # Check if file is present in data folder\n",
    "    return os.path.isfile(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_recording(row, setting, min_length=120):\n",
    "    \"\"\"\n",
    "    Get the available recording of the specified participant in the specified setting (self_local if available, otherwise self_remote).\n",
    "    If duration of self_local recording is less than 2 minutes or the file is unavailable, use self_remote recording.\n",
    "    If duration of self_remote recording is also less than 2 minutes or the file is also unavailable, return None.\n",
    "\n",
    "    Args:\n",
    "    - row (pd.Series): The row of the evaluation questionnaire dataframe.\n",
    "    - setting (str): The setting of the questionnaire data (i.e., \"conv\" or \"coll\").\n",
    "    - min_length (int): The minimum length of the recording in seconds (default is 120 seconds).\n",
    "\n",
    "    Returns:\n",
    "    - str: The available recording of the specified participant in the specified setting.\n",
    "    \"\"\"\n",
    "    # Check if the self_local recording is available and meets the minimum length requirement\n",
    "    if row[f\"Availability_{setting}_rec_self_local\"] == 1 and row[f\"duration_{setting}_rec_self_local\"] >= min_length and available_file(row[f\"{setting}_rec_self_local\"], setting, row[\"batchID\"]):\n",
    "        return row[f\"{setting}_rec_self_local\"]\n",
    "    # Check if the self_remote recording is available and meets the minimum length requirement\n",
    "    elif row[f\"Availability_{setting}_rec_self_remote\"] == 1 and row[f\"duration_{setting}_rec_self_remote\"] >= min_length and available_file(row[f\"{setting}_rec_self_remote\"], setting, row[\"batchID\"]):\n",
    "        return row[f\"{setting}_rec_self_remote\"]\n",
    "    # Otherwise, return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_participant_recordings(df, setting):\n",
    "    \"\"\"\n",
    "    Add a new column to the dataframe with the available recording for the specified participant in the specified setting.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): The dataframe containing the questionnaire data.\n",
    "    - setting (str): The setting of the questionnaire data (i.e., \"conv\" or \"coll\").\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The filtered dataframe with available recordings.\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    df = df.copy()\n",
    "\n",
    "    # Get the available recording for each participant in the specified setting\n",
    "    df[\"recording_file\"] = df.apply(lambda row: available_recording(row, setting), axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with available participant recordings for conversation setting\n",
    "recordings_conv = create_participant_recordings(filtered_reciprocal_conv, \"conv\")\n",
    "\n",
    "# Create dataframe with available participant recordings for collaboration setting\n",
    "recordings_coll = create_participant_recordings(filtered_reciprocal_coll, \"coll\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep dyads with available recordings for both participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_recordings_dyadID(df):\n",
    "    \"\"\"\n",
    "    Get the unique dyadID values where recording is unavailable in the questionnaire data.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): The dataframe containing the (conv or coll) questionnaire data including available participant recordings.\n",
    "\n",
    "    Returns:\n",
    "    - set: The set of dyadIDs with missing recordings in the questionnaire data.\n",
    "    \"\"\"\n",
    "    # Find dyadIDs with missing recordings\n",
    "    missing_rec = df[df[\"recording_file\"].isnull()][\"dyadID\"].unique()\n",
    "\n",
    "    # Remove duplicates\n",
    "    return set(missing_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find dyadIDs with missing recordings in the conversation or collaboration setting\n",
    "missing_dyads = missing_recordings_dyadID(recordings_conv) | missing_recordings_dyadID(recordings_coll)\n",
    "\n",
    "# Show the number of dyads with missing recordings in one (or both) settings\n",
    "print(f\"There are {len(missing_dyads)} dyads with missing recordings in one (or both) settings: {missing_dyads}.\")\n",
    "\n",
    "# Remove these dyads from the participant recordings\n",
    "filtered_recordings_conv = recordings_conv[~recordings_conv[\"dyadID\"].isin(missing_dyads)]\n",
    "filtered_recordings_coll = recordings_coll[~recordings_coll[\"dyadID\"].isin(missing_dyads)]\n",
    "\n",
    "# Print the number of rows in the filtered dataframes\n",
    "print(\"Conversation recordings filtered on missing recordings:\", filtered_recordings_conv.shape)\n",
    "print(\"Collaboration recordings filtered on missing recordings:\", filtered_recordings_coll.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure of Filtering Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of observations before/after each filtering step\n",
    "conv_steps = [questionnaires_conv.shape[0], filtered_questionnaires_conv.shape[0], filtered_reciprocal_conv.shape[0], filtered_recordings_conv.shape[0]]\n",
    "coll_steps = [questionnaires_coll.shape[0], filtered_questionnaires_coll.shape[0], filtered_reciprocal_coll.shape[0], filtered_recordings_coll.shape[0]]\n",
    "\n",
    "# The filtering steps\n",
    "names_steps = [\"Initial\", \"Batches\", \"Reciprocity\", \"Recordings\"]\n",
    "\n",
    "x = np.arange(len(names_steps))  # the label locations\n",
    "width = 0.35  # width of the bars\n",
    "\n",
    "# Create a bar plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars1 = ax.bar(x - width/2, conv_steps, width, label='Conversation', color='limegreen')\n",
    "bars2 = ax.bar(x + width/2, coll_steps, width, label='Collaboration', color='orange')\n",
    "\n",
    "# Add exact values on top of each bar\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 5),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "# Labels and titles\n",
    "ax.set_xlabel('Filtering Step')\n",
    "ax.set_ylabel('Number of Observations (max 2 per dyad)')\n",
    "ax.set_title('Remaining Observations after each Filtering Step')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(names_steps)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retain only Columns of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_conv = filtered_recordings_conv[[\"selfPID\", \"otherPID\", \"dyadID\", \"batchID\", \"conv_CC_rapp1\", \"recording_file\"]]\n",
    "final_df_coll = filtered_recordings_coll[[\"selfPID\", \"otherPID\", \"dyadID\", \"batchID\", \"coll_CC_rapp1\", \"recording_file\"]]\n",
    "\n",
    "print(f\"Number of rows in the dataframes: {final_df_conv.shape[0]} and {final_df_coll.shape[0]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique selfPID\n",
    "unique_selfPID_conv = final_df_conv[\"selfPID\"].nunique()\n",
    "unique_selfPID_coll = final_df_coll[\"selfPID\"].nunique()\n",
    "\n",
    "# Count number of participants in conversation and collaboration\n",
    "print(f\"Number of participants in conversation: {unique_selfPID_conv}\")\n",
    "print(f\"Number of participants in collaboration: {unique_selfPID_coll}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the intake questionnaire to only include participants in the final (conv or coll) dataframes\n",
    "subset_questionnaire_intake = questionnaire_intake[questionnaire_intake[\"globalPID\"].isin(final_df_conv[\"selfPID\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age of participants in the subset\n",
    "age_participants = subset_questionnaire_intake[\"Age_part\"]\n",
    "\n",
    "# Mean\n",
    "mean_age = age_participants.mean()\n",
    "print(f\"Mean age of participants: {mean_age}\")\n",
    "\n",
    "# Standard deviation\n",
    "std_age = age_participants.std()\n",
    "print(f\"Standard deviation of age of participants: {std_age}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender of participants in the subset\n",
    "gender_participants = subset_questionnaire_intake[\"Sex_part\"]\n",
    "\n",
    "# Count females\n",
    "females = gender_participants[gender_participants == \"Female\"].count()\n",
    "print(f\"Number of females: {females}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nationalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of nationalities in the original dataset\n",
    "original_nationalities = questionnaire_intake[\"Nat_part\"]\n",
    "print(f\"Number of nationalities: {len(original_nationalities.unique())}\")\n",
    "print(f\"Nationalities: {original_nationalities.value_counts()}\")\n",
    "\n",
    "# Distribution of nationalities in the subset\n",
    "nationality_participants = subset_questionnaire_intake[\"Nat_part\"]\n",
    "print(f\"Number of nationalities: {len(nationality_participants.unique())}\")\n",
    "print(f\"Nationalities: {nationality_participants.value_counts()}\")\n",
    "\n",
    "# Nationalities not present in the subset that were present in the complete dataset\n",
    "print(f\"Missing nationalities: {set(original_nationalities.unique()) - set(nationality_participants.unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Rapport Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of rapport ratings per level\n",
    "conv_counts = final_df_conv[\"conv_CC_rapp1\"].value_counts().sort_index()\n",
    "coll_counts = final_df_coll[\"coll_CC_rapp1\"].value_counts().sort_index()\n",
    "\n",
    "# Custom x-axis labels\n",
    "x_labels = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Position of the bars\n",
    "x = np.arange(len(x_labels))  # x locations for the groups\n",
    "width = 0.35  # width of the bars\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create bars for Conversation and Collaboration settings\n",
    "bars1 = ax.bar(x - width/2, conv_counts, width, label='Conversation', color='limegreen')\n",
    "bars2 = ax.bar(x + width/2, coll_counts, width, label='Collaboration', color='orange')\n",
    "\n",
    "# Add exact values on top of each bar\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 5),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel(\"Rapport Ratings\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Rapport Ratings in Conversation and Collaboration Settings\")\n",
    "\n",
    "# Customize the x-axis tick labels\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(x_labels)\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Add gridlines for better readability\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust the layout to prevent clipping\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Data of each Dyad into One Row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dyad_rows(df, setting):\n",
    "    \"\"\"\n",
    "    Merge the dataframe with itself to find reciprocal dyad rows and combine them.\n",
    "    In other words, this would result in two times less rows.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): The dataframe containing the questionnaire data.\n",
    "    - setting (str): The setting of the questionnaire data (i.e., \"conv\" or \"coll\").\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The combined dataframe.\n",
    "    \"\"\"\n",
    "    # Merge the dataframe with itself to find reciprocal rows\n",
    "    merged_df = df.merge(df,\n",
    "        left_on=[\"selfPID\", \"otherPID\", \"dyadID\", \"batchID\"],\n",
    "        right_on=[\"otherPID\", \"selfPID\", \"dyadID\", \"batchID\"],\n",
    "        suffixes=(\"_self\", \"_other\")\n",
    "    )\n",
    "\n",
    "    # Select and rename the desired columns\n",
    "    df_combined = merged_df[[\n",
    "        \"selfPID_self\", \"otherPID_self\", \"dyadID\", \"batchID\",\n",
    "        f\"{setting}_CC_rapp1_self\", f\"{setting}_CC_rapp1_other\",\n",
    "        \"recording_file_self\", \"recording_file_other\"\n",
    "    ]].rename(columns={\n",
    "        \"selfPID_self\": \"selfPID\",\n",
    "        \"otherPID_self\": \"otherPID\",\n",
    "        f\"{setting}_CC_rapp1_self\": f\"self_{setting}_CC_rapp1\",\n",
    "        f\"{setting}_CC_rapp1_other\": f\"other_{setting}_CC_rapp1\",\n",
    "        \"recording_file_self\": \"self_recording_file\",\n",
    "        \"recording_file_other\": \"other_recording_file\"\n",
    "    })\n",
    "\n",
    "    # Drop duplicate rows based on dyadID\n",
    "    df_combined = df_combined.drop_duplicates(subset=[\"dyadID\"])\n",
    "\n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine dyad rows in the conversation dataframe\n",
    "final_df_combined_conv = combine_dyad_rows(final_df_conv, \"conv\")\n",
    "\n",
    "# Combine dyad rows in the collboartion dataframe\n",
    "final_df_combined_coll = combine_dyad_rows(final_df_coll, \"coll\")\n",
    "\n",
    "print(f\"Number of rows in the combined dataframes: {final_df_combined_conv.shape[0]} and {final_df_combined_coll.shape[0]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Time and Intensity Values (from trimmed sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sound(recording_file, setting, batch_id):\n",
    "    \"\"\"\n",
    "    Extract the audio sound from the specified recording file.\n",
    "\n",
    "    Args:\n",
    "    - recording_file (str): The name of the recording file.\n",
    "    - setting (str): The setting of the recording file (i.e., \"conv\" or \"coll\").\n",
    "    - batch_id (str): The batchID value of the recording file (e.g. \"Batch_8\").\n",
    "\n",
    "    Returns:\n",
    "    - parselmouth.Sound: The audio sound from the recording file.\n",
    "    \"\"\"\n",
    "    # Define the file path based on batch_id and setting\n",
    "    if setting == \"conv\":\n",
    "        file_path = f\"data/Conversation/WAV_recordings/{batch_id}/{recording_file}.wav\"\n",
    "    elif setting == \"coll\":\n",
    "        file_path = f\"data/Collaboration/WAV_recordings/{batch_id}/{recording_file}.wav\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid setting. Please specify 'conv' or 'coll'.\")\n",
    "\n",
    "    # Load the recording file\n",
    "    sound = parselmouth.Sound(file_path)\n",
    "    \n",
    "    return sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(sound, duration=180):\n",
    "    \"\"\"\n",
    "    Trim the sound to the specified duration (default is 180 seconds).\n",
    "\n",
    "    Args:\n",
    "    - sound (parselmouth.Sound): The audio data from the recording file.\n",
    "    - duration (int): The duration to trim the recording in seconds (default is 180 seconds).\n",
    "\n",
    "    Returns:\n",
    "    - parselmouth.Sound: The trimmed sound.\n",
    "    - float: The new duration of the sound in seconds.\n",
    "    \"\"\"\n",
    "    # Get the duration of the recording\n",
    "    duration_sound = sound.get_total_duration()\n",
    "\n",
    "    # Trim the recording to the specified duration\n",
    "    if duration_sound > duration:\n",
    "        sound = sound.extract_part(from_time=0, to_time=duration)\n",
    "\n",
    "    new_duration = sound.get_total_duration()\n",
    "\n",
    "    return sound, new_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_intensity(sound):\n",
    "    \"\"\"\n",
    "    Extract time and intensity values from the sound.\n",
    "\n",
    "    Args:\n",
    "    - sound (parselmouth.Sound): The audio sound.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: The time values.\n",
    "    - np.array: The intensity values.\n",
    "    \"\"\"\n",
    "    # Convert the sound to intensity\n",
    "    intensity = sound.to_intensity()\n",
    "\n",
    "    # Extract time and intensity values\n",
    "    time_values = intensity.xs()\n",
    "    intensity_values = intensity.values.T\n",
    "    \n",
    "    return time_values, intensity_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_turns(time_values, intensity_values, threshold=50, max_pause_duration=0.2):\n",
    "    \"\"\"\n",
    "    Extract turns from the time and intensity values.\n",
    "\n",
    "    Args:\n",
    "    - time_values (np.array): The time values.\n",
    "    - intensity_values (np.array): The intensity values.\n",
    "    - threshold (int): The intensity threshold for detecting voiced frames (default is 50).\n",
    "    - max_pause_duration (float): The maximum allowed pause duration within turns (default is 0.2 seconds).\n",
    "    \n",
    "    Returns:\n",
    "    - list of tuples: [(start_time, end_time), ...] representing the turns.\n",
    "    \"\"\"\n",
    "    # Identify voiced frames where intensity exceeds the thresholds\n",
    "    voiced = intensity_values >= threshold\n",
    "\n",
    "    # Initialize variables\n",
    "    turns = [] # List to store turns\n",
    "    start = None # Start of a turn\n",
    "    last_voiced = None # Last voiced frame\n",
    "    \n",
    "    # Find consective voiced frames\n",
    "    for t in range(len(time_values)):\n",
    "        if voiced[t] and start is None: # Start of a turn\n",
    "            start = time_values[t]\n",
    "            last_voiced = t\n",
    "        elif voiced[t] and start is not None: # Continue a turn\n",
    "            last_voiced = t\n",
    "        elif not voiced[t] and start is not None and (time_values[t] - time_values[last_voiced]) >= max_pause_duration: # End of a turn\n",
    "            if time_values[last_voiced] - start > 0: # Only add if the turn is longer than 0 seconds\n",
    "                turns.append((start, time_values[last_voiced])) # Turn: start until last voiced\n",
    "\n",
    "            # Reset start and last_voiced\n",
    "            start = None\n",
    "            last_voiced = None\n",
    "\n",
    "    # End the last started turn\n",
    "    if start is not None:\n",
    "        turns.append((start, time_values[last_voiced]))\n",
    "            \n",
    "    return turns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Conversation Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlapping_turns(turn, turns):\n",
    "    \"\"\"\n",
    "    Get the (partly) overlapping turns of a turn.\n",
    "\n",
    "    Args:\n",
    "    - turn (start_time, end_time): The turn of interest.\n",
    "    - turns2 (list of tuples): [(start_time, end_time), ...] representing the turns to compare.\n",
    "\n",
    "    Returns:\n",
    "    - list of tuples: [(start_time, end_time), ...] representing the (partly) overlapping turns.\n",
    "    \"\"\"\n",
    "    # Condition 1: Turn of interest starts within another turn in turns\n",
    "    condition1 = [t for t in turns if t[0] <= turn[0] <= t[1]]\n",
    "\n",
    "    # Condition 2: Turn of interest ends within another turn in turns\n",
    "    condition2 = [t for t in turns if t[0] <= turn[1] <= t[1]]\n",
    "\n",
    "    # Condition 3: Turn of interest starts before another turn and ends after another turn\n",
    "    condition3 = [t for t in turns if turn[0] <= t[0] <= t[1] <= turn[1]]\n",
    "\n",
    "    # Create a union of three lists (turns that satisfy any of the conditions)\n",
    "    union = condition1 + condition2 + condition3\n",
    "\n",
    "    # Remove duplicates\n",
    "    return list(set(union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_turn_lengths(turns1, turns2):\n",
    "    \"\"\"\n",
    "    Get the turn length of the first participant (i.e., the durations of uninterrupted speech).\n",
    "\n",
    "    Args:\n",
    "    - turns1 (list of tuples): [(start_time, end_time), ...] representing the turns of the first participant.\n",
    "    - turns2 (list of tuples): [(start_time, end_time), ...] representing the turns of the second participant.\n",
    "\n",
    "    Returns:\n",
    "    - list: The turn lengths for the first participant.\n",
    "    \"\"\"\n",
    "    turn_lengths = [] # List to store the turn lengths\n",
    "\n",
    "    # Iterate through the turns of the first participant\n",
    "    for t1 in range(len(turns1)):\n",
    "        start = turns1[t1][0] # Start of the turn\n",
    "        end = turns1[t1][1] # End of the turn\n",
    "\n",
    "        # Calculate the total length of turn t1\n",
    "        total_length = end - start\n",
    "\n",
    "        # Find turns in turns2 that overlap with turn t1\n",
    "        overlapping_turns = get_overlapping_turns(turns1[t1], turns2)\n",
    "\n",
    "        # Substract overlapping turn lengths\n",
    "        for t2 in overlapping_turns:\n",
    "            if start <= t2[0] and end >= t2[1]: # Completely overlapping\n",
    "                total_length -= t2[1] - t2[0]\n",
    "            elif t2[0] <= start: # Overlapping at the beginning\n",
    "                total_length -= t2[1] - start\n",
    "            else: # Overlapping at the end\n",
    "                total_length -= end - t2[0]\n",
    "\n",
    "        turn_lengths.append(max(total_length, 0)) # Ensure non-negative length\n",
    "\n",
    "    return turn_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaking time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speaking_time(turn_lengths, interaction_duration):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of total speaking time of the speaker of interest.\n",
    "\n",
    "    Args:\n",
    "    - turn_lengths (np.array): The turn lengths of the speaker of interest.\n",
    "    - interaction_duration (int): The total interaction duration in seconds.\n",
    "\n",
    "    Returns:\n",
    "    - float: The percentage of total speaking time for the speaker of interest.\n",
    "    \"\"\"\n",
    "    return (np.sum(turn_lengths) / interaction_duration) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_times(turns1, turns2):\n",
    "    \"\"\"\n",
    "    Calculate the response times of the first speaker.\n",
    "\n",
    "    Args:\n",
    "    - turns1 (list of tuples): [(start_time, end_time), ...] representing turns of the first speaker.\n",
    "    - turns2 (list of tuples): [(start_time, end_time), ...] representing turns of the second speaker.\n",
    "\n",
    "    Returns:\n",
    "    - list: The response times of the first speaker.\n",
    "    \"\"\"\n",
    "    response_times = []\n",
    "\n",
    "    for i, (start, end) in enumerate(turns1):\n",
    "        # Find the last preceding turn of the second speaker\n",
    "        last_turn2 = next((t for t in reversed(turns2) if t[0] <= start), None)\n",
    "\n",
    "        if last_turn2 is None: # No turn found\n",
    "            response_times.append(0) \n",
    "        else: # Turn found\n",
    "            # Calculate the response time of the first speaker, set to 0 if speech overlaps\n",
    "            response_times.append(max(start - last_turn2[1], 0))\n",
    "            \n",
    "    return response_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speech rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_turn(sound, start_time, end_time, model):\n",
    "    \"\"\"\n",
    "    Transcribe the turn segment of the audio sound.\n",
    "\n",
    "    Args:\n",
    "    - sound (parselmouth.Sound): The audio sound.\n",
    "    - start_time (float): The start time of the turn segment.\n",
    "    - end_time (float): The end time of the turn segment.\n",
    "    - model (whisper.Model): The preloaded Whisper model for transcription.\n",
    "\n",
    "    Returns:\n",
    "    - str: The transcription of the turn segment.\n",
    "    \"\"\"\n",
    "    # Extract the turn segment of the audio\n",
    "    segment = sound.extract_part(from_time=start_time, to_time=end_time)\n",
    "\n",
    "    # Save the segment to a temporary WAV file\n",
    "    segment_wav_path = \"temp_segment.wav\"\n",
    "    segment.save(segment_wav_path, \"WAV\")\n",
    "\n",
    "    # Transcribe the audio segment\n",
    "    result = model.transcribe(segment_wav_path)\n",
    "\n",
    "    # Get the transcription text\n",
    "    transcription = result[\"text\"]\n",
    "\n",
    "    # Delete the temporary WAV file\n",
    "    os.remove(segment_wav_path)\n",
    "\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcription_file_name(global_pid, batch_id, dyad_id, setting, start_time, end_time):\n",
    "    \"\"\"\n",
    "    Generate the file name for the transcription based on the parameters.\n",
    "\n",
    "    Args:\n",
    "    - global_pid (int): The global participant ID.\n",
    "    - batch_id (str): The batchID value of the turn (e.g. \"Batch_8\").\n",
    "    - dyad_id (str): The dyadID value of the turn.\n",
    "    - setting (str): The setting of the recording file (i.e., \"conv\" or \"coll\").\n",
    "    - start_time (float): The start time of the turn segment.\n",
    "    - end_time (float): The end time of the turn segment.\n",
    "\n",
    "    Returns:\n",
    "    - str: The file name for the transcription.\n",
    "    \"\"\"\n",
    "    if setting == \"conv\":\n",
    "        return f\"data/Conversation/Transcriptions/{batch_id}/{dyad_id}_{global_pid}_{start_time:.2f}_{end_time:.2f}\"\n",
    "    elif setting == \"coll\":\n",
    "        return f\"data/Collaboration/Transcriptions/{batch_id}/{dyad_id}_{global_pid}_{start_time:.2f}_{end_time:.2f}\"\n",
    "    else:   \n",
    "        raise ValueError(\"Invalid setting. Please specify 'conv' or 'coll'.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_transcription(transcription, file_name):\n",
    "    \"\"\"\n",
    "    Store the transcription in a text file.\n",
    "\n",
    "    Args:\n",
    "    - transcription (str): The transcription text.\n",
    "    - file_name (str): The file name for the transcription.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "\n",
    "    # Write the transcription to the text file\n",
    "    with open(f\"{file_name}.txt\", \"w\") as f:\n",
    "        f.write(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcription(global_pid, batch_id, dyad_id, setting, sound, start_time, end_time, model):\n",
    "    \"\"\"\n",
    "    Get the transcription of the turn segment.\n",
    "    - If the transcription file already exists, read the transcription from the file.\n",
    "    - If the transcription file does not exist, transcribe the turn segment and store it in a text file.\n",
    "\n",
    "    Args:\n",
    "    - global_pid (int): The globalPID of the participant.\n",
    "    - batch_id (str): The batchID value of the turn (e.g. \"Batch_8\").\n",
    "    - dyad_id (str): The dyadID value of the turn.\n",
    "    - setting (str): The setting of the turn (i.e., \"conv\" or \"coll\").\n",
    "    - sound (parselmouth.Sound): The audio sound.\n",
    "    - start_time (float): The start time of the turn segment.\n",
    "    - end_time (float): The end time of the turn segment.\n",
    "    - model (whisper.Model): The preloaded Whisper model for transcription.\n",
    "\n",
    "    Returns:\n",
    "    - str: The transcription of the turn segment.\n",
    "    \"\"\"\n",
    "    # Generate the transcription file name\n",
    "    file_name = transcription_file_name(global_pid, batch_id, dyad_id, setting, start_time, end_time)\n",
    "\n",
    "    # Check if the transcription file already exists\n",
    "    if os.path.isfile(f\"{file_name}.txt\"):\n",
    "        # Extract transcription\n",
    "        with open(f\"{file_name}.txt\", \"r\") as f:\n",
    "            transcription = f.read()\n",
    "    else:\n",
    "        # Transcribe the turn segment and store it in a text file\n",
    "        transcription = transcribe_turn(sound, start_time, end_time, model)\n",
    "        store_transcription(transcription, file_name)\n",
    "    \n",
    "    return transcription\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wpm(transcription, duration_minutes):\n",
    "    \"\"\"\n",
    "    Calculate the words per minute (WPM) of the transcription.\n",
    "\n",
    "    Args:\n",
    "    - transcription (str): The transcription of the turn segment.\n",
    "    - duration_minutes (float): The duration of the turn segment in minutes.\n",
    "\n",
    "    Returns:\n",
    "    - float: The words per minute (WPM) of the turn.\n",
    "    \"\"\"\n",
    "    # Count the number of words in the transcription\n",
    "    words = re.findall(r'\\b\\w+\\b', transcription)\n",
    "    num_words = len(words)\n",
    "\n",
    "    # Calculate the words per minute (WPM)\n",
    "    wpm = num_words / duration_minutes if duration_minutes > 0 else 0\n",
    "\n",
    "    return wpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speech_rates(global_pid, batch_id, dyad_id, setting, turns, sound, model):\n",
    "    \"\"\"\n",
    "    Calculate the speech rate (words per minute) for each turn.\n",
    "\n",
    "    Args:\n",
    "    - global_pid (int): The globalPID of the participant.\n",
    "    - batch_id (str): The batchID value of the turn (e.g. \"Batch_8\").\n",
    "    - dyad_id (str): The dyadID value of the turn.\n",
    "    - setting (str): The setting of the turn (i.e., \"conv\" or \"coll\").\n",
    "    - turns (list of tuples): [(start_time, end_time), ...] representing turns.\n",
    "    - sound (parselmouth.Sound): The audio sound.\n",
    "    - model (whisper.Model): The preloaded Whisper model for transcription.\n",
    "\n",
    "    Returns:\n",
    "    - list: The speech rates for each turn.\n",
    "    \"\"\"\n",
    "    speech_rates = []\n",
    "\n",
    "    # Calculate words per minute in each turn\n",
    "    for start_time, end_time in turns:\n",
    "        # Get the transcription of the turn\n",
    "        transcription = get_transcription(global_pid, batch_id, dyad_id, setting, sound, start_time, end_time, model)\n",
    "\n",
    "        # Calculate the duration of the turn in minutes\n",
    "        duration_minutes = (end_time - start_time) / 60\n",
    "\n",
    "        # Calculate the words per minute (WPM) of the turn\n",
    "        wpm = calculate_wpm(transcription, duration_minutes)\n",
    "        speech_rates.append(wpm)\n",
    "\n",
    "    return speech_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the four conversation dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation_dynamics(self_recording_file, other_recording_file, setting, batch_id, dyad_id, self_global_pid, other_global_pid, model):\n",
    "    \"\"\"\n",
    "    Extract the conversation dynamics from the recording files of the self and other participant.\n",
    "\n",
    "    Args:\n",
    "    - self_recording_file (str): The name of the self participant recording file.\n",
    "    - other_recording_file (str): The name of the other participant recording file.\n",
    "    - setting (str): The setting of the recording files (i.e., \"conv\" or \"coll\").\n",
    "    - batch_id (str): The batchID value of the recording files (e.g. \"Batch_8\").\n",
    "    - dyad_id (str): The dyadID value of the recording files.\n",
    "    - self_global_pid (int): The globalPID of the self participant.\n",
    "    - other_global_pid (int): The globalPID of the other participant.\n",
    "    - model (whisper.Model): The preloaded Whisper model for transcription (speech rate).\n",
    "    \n",
    "    Returns:\n",
    "    - list of tuples: [(start_time, end_time), ...] representing the turns of the self participant.\n",
    "    - list: The conversation dynamics of the self participant.\n",
    "    - list of tuples: [(start_time, end_time), ...] representing the turns of the other participant.\n",
    "    - list: The conversation dynamics of the other participant.\n",
    "    \"\"\"\n",
    "    # Extract the sounds from the recording files\n",
    "    self_snd = extract_sound(self_recording_file, setting, batch_id)\n",
    "    other_snd = extract_sound(other_recording_file, setting, batch_id)\n",
    "\n",
    "    # Trim the sounds to 3 minutes\n",
    "    self_snd, self_snd_duration = trim(self_snd)\n",
    "    other_snd, other_snd_duration = trim(other_snd)\n",
    "\n",
    "    # Extract the time and intensity values\n",
    "    self_time_values, self_intensity_values = extract_time_intensity(self_snd)\n",
    "    other_time_values, other_intensity_values = extract_time_intensity(other_snd)\n",
    "\n",
    "    # Extract the turns\n",
    "    self_turns = get_turns(self_time_values, self_intensity_values)\n",
    "    other_turns = get_turns(other_time_values, other_intensity_values)\n",
    "\n",
    "    # Extract the turn lengths\n",
    "    self_turn_lengths = get_turn_lengths(self_turns, other_turns)\n",
    "    other_turn_lengths = get_turn_lengths(other_turns, self_turns)\n",
    "\n",
    "    # Extract the speaking time\n",
    "    self_speaking_time = get_speaking_time(self_turn_lengths, self_snd_duration)\n",
    "    other_speaking_time = get_speaking_time(other_turn_lengths, other_snd_duration)\n",
    "    \n",
    "    # Extract the speech rates\n",
    "    self_speaking_rate = get_speech_rates(self_global_pid, batch_id, dyad_id, setting, self_turns, self_snd, model)\n",
    "    other_speaking_rate = get_speech_rates(other_global_pid, batch_id, dyad_id, setting, other_turns, other_snd, model)\n",
    "\n",
    "    # Extract the response times\n",
    "    self_response_times = get_response_times(self_turns, other_turns)\n",
    "    other_response_times = get_response_times(other_turns, self_turns)\n",
    "\n",
    "    return self_turns, [self_speaking_time, self_turn_lengths, self_speaking_rate, self_response_times], other_turns, [other_speaking_time, other_turn_lengths, other_speaking_rate, other_response_times]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Measures of Conversation Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_time_series(self_turns, self_conversation_dynamic, other_turns, other_conversation_dynamic):\n",
    "    \"\"\"\n",
    "    Align the conversation dynamic timelines (self speaker t <-> other speaker t - 1).\n",
    "    If one participant had consecutive turns without the other participant intervening, \n",
    "    we averaged the conversation dynamics of those consecutive turns.\n",
    "\n",
    "    Args:\n",
    "    - self_turns (list of tuples): [(start_time, end_time), ...] representing the turns of the self participant.\n",
    "    - self_conversation_dynamic (list): The conversation dynamics of the self participant.\n",
    "    - other_turns (list of tuples): [(start_time, end_time), ...] representing the turns of the other participant.\n",
    "    - other_conversation_dynamic (list): The conversation dynamics of the other participant.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: The aligned conversation dynamic values for the self participant.\n",
    "    - np.array: The aligned conversation dynamic values for the other participant.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store the aligned conversation dynamics\n",
    "    aligned_self_conversation_dynamics = []\n",
    "    aligned_other_conversation_dynamics = []\n",
    "\n",
    "    other_t = 0 # First turn of the other participant\n",
    "\n",
    "    # First turn of the self participant following a turn of the other participant\n",
    "    self_t = next((i for i, t in enumerate(self_turns) if t[0] > other_turns[other_t][0]), len(self_turns))\n",
    "\n",
    "    # Keep track of the current speaker turn\n",
    "    current = \"other\" # \"self\" or \"other\"\n",
    "    consecutive_turns = 0 # Number of consecutive turns\n",
    "    current_dynamic_sum = 0 # Sum of the conversation dynamics for the current speaker turn\n",
    "\n",
    "    # Iterate through the turns of both participants\n",
    "    while self_t < len(self_turns) and other_t < len(other_turns):\n",
    "        # Find the current turn for both participants\n",
    "        self_turn = self_turns[self_t][0]\n",
    "        other_turn = other_turns[other_t][0]\n",
    "\n",
    "        # Check if the current speaker is the other participant\n",
    "        if current == \"other\":\n",
    "            if self_turn <= other_turn: # End aligned turn\n",
    "                # Calculate the average conversation dynamic\n",
    "                aligned_other_conversation_dynamics.append(current_dynamic_sum / consecutive_turns)\n",
    "\n",
    "                # Update the current speaker to the self participant\n",
    "                current = \"self\"\n",
    "                consecutive_turns = 0\n",
    "                current_dynamic_sum = 0\n",
    "\n",
    "            else: # Continue aligned turn\n",
    "                consecutive_turns += 1 # Increase the number of consecutive turns\n",
    "                current_dynamic_sum += other_conversation_dynamic[other_t] # Add the current conversation dynamic\n",
    "\n",
    "                # Move to the next turn of the other participant\n",
    "                other_t += 1\n",
    "\n",
    "        else: # Check if the current speaker is the self participant\n",
    "            if self_turn <= other_turn: # Continue aligned turn\n",
    "                consecutive_turns += 1 # Increase the number of consecutive turns\n",
    "                current_dynamic_sum += self_conversation_dynamic[self_t] # Add the current conversation dynamic\n",
    "\n",
    "                # Move to the next turn of the self participant\n",
    "                self_t += 1\n",
    "\n",
    "            else: # End aligned turn\n",
    "                # Calculate the average conversation dynamic\n",
    "                aligned_self_conversation_dynamics.append(current_dynamic_sum / consecutive_turns)\n",
    "\n",
    "                # Update the current speaker to the other participant\n",
    "                current = \"other\"\n",
    "                consecutive_turns = 0\n",
    "                current_dynamic_sum = 0\n",
    "\n",
    "    # Handle the last turn\n",
    "    if current == \"self\": # Last turn was from the self participant\n",
    "        aligned_self_conversation_dynamics.append(current_dynamic_sum / consecutive_turns)\n",
    "    else: # Last turn was from the other participant\n",
    "        aligned_other_conversation_dynamics.append(current_dynamic_sum / consecutive_turns)\n",
    "\n",
    "        # Combine the remaining turns of the self participant\n",
    "        consecutive_turns = 0\n",
    "        current_dynamic_sum = 0\n",
    "\n",
    "        for i in range(self_t, len(self_turns)):\n",
    "            consecutive_turns += 1\n",
    "            current_dynamic_sum += self_conversation_dynamic[i]\n",
    "\n",
    "        aligned_self_conversation_dynamics.append(current_dynamic_sum / consecutive_turns)\n",
    "\n",
    "    # Remove the last element of the other participant's conversation dynamics if it is longer than the self participant's\n",
    "    # This is done to ensure that conversation dynamics lists have the same length\n",
    "    if len(aligned_other_conversation_dynamics) > len(aligned_self_conversation_dynamics):\n",
    "        aligned_other_conversation_dynamics = aligned_other_conversation_dynamics[:-1] # Remove the last element\n",
    "\n",
    "    return aligned_self_conversation_dynamics, aligned_other_conversation_dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measures(self_turns, self_conversation_dynamic, other_turns, other_conversation_dynamic):\n",
    "    \"\"\"\n",
    "    Calculate the median, coefficient of variation, adaptability and predictability of \n",
    "    the values of a specific conversation dynamic of the self participant.\n",
    "\n",
    "    Args:\n",
    "    - self_turns (list of tuples): [(start_time, end_time), ...] representing the turns of the self participant.\n",
    "    - self_conversation_dynamic (list): The values of a specific conversation dynamic of the self participant.\n",
    "    - other_turns (list of tuples): [(start_time, end_time), ...] representing the turns of the other participant.\n",
    "    - other_conversation_dynamic (list): The values of a specific conversation dynamic of the other participant.\n",
    "\n",
    "    Returns:\n",
    "    - float: The median value of the conversation dynamic.\n",
    "    - float: The coefficient of variation of the conversation dynamic.\n",
    "    - float: The adaptability of the conversation dynamic.\n",
    "    - float: The predictability of the conversation dynamic.\n",
    "    \"\"\"\n",
    "    # Median\n",
    "    median = np.median(self_conversation_dynamic)\n",
    "\n",
    "    # Coefficient of variation (i.e., ratio between the standard deviation and the mean)\n",
    "    if np.mean(self_conversation_dynamic) > 0:\n",
    "        variation = np.std(self_conversation_dynamic) / np.mean(self_conversation_dynamic)\n",
    "    else:\n",
    "        variation = 0\n",
    "\n",
    "    self_aligned_conversation_dynamic, other_aligned_conversation_dynamic = align_time_series(self_turns, self_conversation_dynamic, other_turns, other_conversation_dynamic)\n",
    "\n",
    "    # Adaptability (i.e., Spearman correlation between conversation dynamic values of the first at time t and second speaker at time t - 1)\n",
    "    if len(self_conversation_dynamic) > 1:\n",
    "        adaptability = np.corrcoef(self_aligned_conversation_dynamic, other_aligned_conversation_dynamic)[0, 1]\n",
    "\n",
    "    # Predictability (i.e., Spearman correlation between conversation dynamic values at time t and t - 1)\n",
    "    if len(self_conversation_dynamic) > 1:\n",
    "        predictability = np.corrcoef(self_conversation_dynamic[1:], self_conversation_dynamic[:-1])[0, 1]\n",
    "\n",
    "    return median, variation, adaptability, predictability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_measures(df, setting, names_conversation_dynamics, names_measures, model):\n",
    "    \"\"\"\n",
    "    Store the conversation dynamics measures in the dataframe.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): The dataframe containing the questionnaire data.\n",
    "    - setting (str): The setting of the questionnaire data (i.e., \"conv\" or \"coll\").\n",
    "    - names_conversation_dynamics (list): The names of the conversation dynamics.\n",
    "    - names_measures (list): The names of the measures.\n",
    "    - model (whisper.Model): The preloaded Whisper model for transcription (speech rate).\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The dataframe with the conversation dynamics measures.\n",
    "    \"\"\"\n",
    "    # Create a new dataframe to store the conversation dynamics measures\n",
    "    df_measures = df.copy()\n",
    "\n",
    "    # Iterate over the dataframe\n",
    "    # for interaction in df_measures.itertuples():\n",
    "    for interaction in tqdm(df_measures.itertuples(), total=len(df_measures), desc=f\"Processing {setting} interactions\"):\n",
    "        # Extract the conversation dynamics for each dyad\n",
    "        self_turns, self_conversation_dynamics, other_turns, other_conversation_dynamics = conversation_dynamics(\n",
    "            interaction.self_recording_file,\n",
    "            interaction.other_recording_file,\n",
    "            setting,\n",
    "            interaction.batchID,\n",
    "            interaction.dyadID,\n",
    "            interaction.selfPID,\n",
    "            interaction.otherPID,\n",
    "            model\n",
    "    )\n",
    "\n",
    "        # Store speaking time in the dataframe\n",
    "        df_measures.loc[interaction.Index, \"self_speaking_time\"] = self_conversation_dynamics[0]\n",
    "        df_measures.loc[interaction.Index, \"other_speaking_time\"] = other_conversation_dynamics[0]\n",
    "\n",
    "        for c in range(1, len(self_conversation_dynamics)): # Skip the first element (i.e., speaking time)\n",
    "            # Calculate the measures for the self participant\n",
    "            self_measures = get_measures(self_turns, self_conversation_dynamics[c], other_turns, other_conversation_dynamics[c])\n",
    "\n",
    "            # Store the measures in the dataframe\n",
    "            for m in range(len(self_measures)):\n",
    "                df_measures.loc[interaction.Index, f\"self_{names_conversation_dynamics[c]}_{names_measures[m]}\"] = self_measures[m]\n",
    "\n",
    "            # Calculate the measures for the other participant\n",
    "            other_measures = get_measures(other_turns, other_conversation_dynamics[c], self_turns, self_conversation_dynamics[c])\n",
    "\n",
    "            # Store the measures in the dataframe\n",
    "            for m in range(len(other_measures)):\n",
    "                df_measures.loc[interaction.Index, f\"other_{names_conversation_dynamics[c]}_{names_measures[m]}\"] = other_measures[m]\n",
    "\n",
    "    return df_measures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Computation to the Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Whisper model for transcription\n",
    "model = whisper.load_model(\"base.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of the conversation dynamics and measures\n",
    "names_conversation_dynamics = [\"speaking_time\", \"turn_lengths\", \"speaking_rate\", \"response_times\"]\n",
    "names_measures = [\"median\", \"variability\", \"adaptability\", \"predictability\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and store measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress a specific warning (that occurs often but is not important for us)\n",
    "warnings.filterwarnings(\"ignore\", message=\"FP16 is not supported on CPU; using FP32 instead\")\n",
    "\n",
    "df_measures_conv = store_measures(final_df_combined_conv, \"conv\", names_conversation_dynamics, names_measures, model)\n",
    "df_measures_coll = store_measures(final_df_combined_coll, \"coll\", names_conversation_dynamics, names_measures, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(df, setting):\n",
    "    \"\"\"\n",
    "    Split the dyad rows into two rows: one for self participant and one for other participant.\n",
    "    In other words, this would result in two times more rows.\n",
    "    \n",
    "    For the self participant, the self_ and other_ columns are kept as is.\n",
    "    For the other participant, the self_ and other_ columns are swapped.\n",
    "    \n",
    "    Perceived rapport values are put into the column 'rapport'.\n",
    "    The original self_{setting}_CC_rapp1 and other_{setting}_CC_rapp1 columns are dropped.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): The dataframe containing the questionnaire data.\n",
    "    - setting (str): The setting of the questionnaire data (i.e., \"conv\" or \"coll\").\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The transformed dataframe.\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe\n",
    "    df_transformed = df.copy()\n",
    "\n",
    "    # Create a new column 'rapport' and assign values from 'self_{setting}_CC_rapp1'\n",
    "    df_transformed['rapport'] = df_transformed[f'self_{setting}_CC_rapp1']\n",
    "\n",
    "    # Create rows for 'other_{setting}_CC_rapp1' with swapped values\n",
    "    other_rows = df_transformed.copy()\n",
    "    other_rows['rapport'] = df_transformed[f'other_{setting}_CC_rapp1']\n",
    "\n",
    "    # Swap self_ and other_ columns for the 'other' rows\n",
    "    for col in df_transformed.columns:\n",
    "        if col.startswith('self'):\n",
    "            other_rows[col] = df_transformed[col.replace('self', 'other')]\n",
    "        elif col.startswith('other'):\n",
    "            other_rows[col] = df_transformed[col.replace('other', 'self')]\n",
    "\n",
    "    # Concatenate the original and transformed ('other') rows\n",
    "    df_combined = pd.concat([df_transformed, other_rows], ignore_index=True)\n",
    "\n",
    "    # Drop the original self_{setting}_CC_rapp1 and other_{setting}_CC_rapp1 columns\n",
    "    df_combined = df_combined.drop(columns=[f'self_{setting}_CC_rapp1', f'other_{setting}_CC_rapp1'])\n",
    "\n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dyad rows of the dataframes into participant-specific rows\n",
    "df_split_measures_conv = split_rows(df_measures_conv, \"conv\")\n",
    "df_split_measures_coll = split_rows(df_measures_coll, \"coll\")\n",
    "\n",
    "print(\"Number of rows in the original dataframes:\", df_measures_conv.shape[0], \"and\", df_measures_coll.shape[0])\n",
    "print(\"Number of rows in the split dataframes:\", df_split_measures_conv.shape[0], \"and\", df_split_measures_coll.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies of the dataframes\n",
    "df_split_measures_conv_copy = df_split_measures_conv.copy()\n",
    "df_split_measures_coll_copy = df_split_measures_coll.copy()\n",
    "\n",
    "# Combine the dataframes by introducing a new column 'setting'\n",
    "df_split_measures_conv_copy[\"setting\"] = 0\n",
    "df_split_measures_coll_copy[\"setting\"] = 1\n",
    "\n",
    "# Concatenate the dataframes\n",
    "df_split_measures_combined = pd.concat([df_split_measures_conv_copy, df_split_measures_coll_copy], ignore_index=True)\n",
    "df_split_measures_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(df):\n",
    "    \"\"\"\n",
    "    Standardize the numeric columns (except perceived rapport and setting) in the dataframe.\n",
    "    This function groups columns with similar base names, indicating measures (e.g. speaking_time),\n",
    "    and standardizes them together.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): The dataframe containing the data.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The dataframe with standardized columns.\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # All numeric columns\n",
    "    columns = df_copy.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "    # Exclude perceived rapport and setting columns\n",
    "    exclude_columns = [\"rapport\", \"setting\"]\n",
    "    columns = [col for col in columns if col not in exclude_columns]\n",
    "    print('Standardized columns:', columns)\n",
    "    print('Non-standardized columns:', list(df_copy.columns.difference(columns)))\n",
    "\n",
    "    # Group by base name (e.g. speaking_time, turn_lengths, etc.)\n",
    "    grouped = {}\n",
    "    for col in columns:\n",
    "        match = re.match(r'(self|other)_(.+)', col)\n",
    "        if match:\n",
    "            base = match.group(2)\n",
    "            grouped.setdefault(base, []).append(col)\n",
    "        else:\n",
    "            # Handle columns without self_/other_ prefix\n",
    "            grouped.setdefault(col, []).append(col)\n",
    "\n",
    "    print('Groups:', grouped)\n",
    "\n",
    "    # Standardize each group together\n",
    "    for base, cols in grouped.items():\n",
    "        if len(cols) > 1:\n",
    "            values = df_copy[cols].values\n",
    "            scaler = StandardScaler()\n",
    "            df_copy[cols] = scaler.fit_transform(values)\n",
    "        else:\n",
    "            # Standardize solo columns normally\n",
    "            scaler = StandardScaler()\n",
    "            df_copy[cols] = scaler.fit_transform(df_copy[cols])\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stnd_split_measures_conv = standardize(df_split_measures_conv)\n",
    "df_stnd_split_measures_coll = standardize(df_split_measures_coll)\n",
    "df_stnd_split_measures_combined = standardize(df_split_measures_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interaction terms for the self_ and other_ columns with setting\n",
    "for col in df_stnd_split_measures_combined.columns:\n",
    "    if (col.startswith('self_') or col.startswith('other_')) and not col.endswith(\"recording_file\"):\n",
    "        df_stnd_split_measures_combined[f\"setting_x_{col}\"] = df_stnd_split_measures_combined[\"setting\"] * df_stnd_split_measures_combined[col]\n",
    "\n",
    "print(df_stnd_split_measures_combined.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe:\n",
    "- Person ID (globalPID)\n",
    "- Gender (....)\n",
    "- Batch (batchID)\n",
    "- Group size (...)\n",
    "- Setting (Conversation / Collaboration)\n",
    "- Rapport\n",
    "- Conversation dynamics (self)\n",
    "    - Speaking time\n",
    "        - Percentage\n",
    "    - Turn length / Response time / Speech rate:\n",
    "        - Median\n",
    "        - Variation\n",
    "        - Adaptability\n",
    "        - Predictability\n",
    "- Conversation dynamics (other)\n",
    "    - Speaking time\n",
    "        - Percentage\n",
    "    - Turn length / Response time / Speech rate:\n",
    "        - Median\n",
    "        - Variation\n",
    "        - Adaptability\n",
    "        - Predictability\n",
    "<!-- - Participant 1 (PID)\n",
    "- Gender participant 1 \n",
    "- Participant 2 (PID)\n",
    "- Gender participant 2\n",
    "- Batch (batchID)\n",
    "- Group size\n",
    "- Setting (Conversation / Collaboration)\n",
    "- Rapport participant 1\n",
    "- Conversation dynamics participant 1\n",
    "    - Speaking time\n",
    "        - Percentage\n",
    "    - Turn length / Response time / Speech rate:\n",
    "        - Median\n",
    "        - Variation\n",
    "        - Adaptability\n",
    "        - Predictability\n",
    "- Conversation dynamics participant 2\n",
    "    - Speaking time\n",
    "        - Percentage\n",
    "    - Turn length / Response time / Speech rate:\n",
    "        - Median\n",
    "        - Variation\n",
    "        - Adaptability\n",
    "        - Predictability -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_matrix(df, setting, include_self, include_other, include_interactions, annotate=False, name_mapping=None):\n",
    "    \"\"\"\n",
    "    Get the correlation matrix of the conversation dynamics measures.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): The dataframe containing the conversation dynamics measures.\n",
    "    - setting (str): The setting of the conversation dynamics measures (i.e., \"conv\", \"coll\" or \"both\").\n",
    "    - include_self (bool): Whether to include the self participant measures in the correlation matrix.\n",
    "    - include_other (bool): Whether to include the other participant measures in the correlation matrix.\n",
    "    - include_interactions (bool): Whether to include the interaction terms in the correlation matrix.\n",
    "    - annotate (bool): Whether to annotate the correlation matrix with the correlation values.\n",
    "    - name_mapping (dict): A dictionary mapping the original technical column names to the new nice readable names.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The correlation matrix of the conversation dynamics measures.\n",
    "    \"\"\"\n",
    "    # Create a list of conversation dynamics measures\n",
    "    conv_dyn_measures = []\n",
    "\n",
    "    # Include the conversation dynamics measures for the self participant\n",
    "    if include_self:\n",
    "        conv_dyn_measures += [\"self_speaking_time\"]\n",
    "        conv_dyn_measures += [f\"self_{c}_{m}\" for c in names_conversation_dynamics[1:] for m in names_measures]\n",
    "    \n",
    "    # Include the conversation dynamics measures for the other participant\n",
    "    if include_other:\n",
    "        conv_dyn_measures += [\"other_speaking_time\"]\n",
    "        conv_dyn_measures += [f\"other_{c}_{m}\" for c in names_conversation_dynamics[1:] for m in names_measures]\n",
    "\n",
    "    # Include the interaction terms\n",
    "    if include_interactions:\n",
    "        conv_dyn_measures += [\"setting\"]\n",
    "        if include_self:\n",
    "            conv_dyn_measures += [f\"setting_x_self_speaking_time\"]\n",
    "            conv_dyn_measures += [f\"setting_x_self_{c}_{m}\" for c in names_conversation_dynamics[1:] for m in names_measures]\n",
    "        if include_other:\n",
    "            conv_dyn_measures += [f\"setting_x_other_speaking_time\"]\n",
    "            conv_dyn_measures += [f\"setting_x_other_{c}_{m}\" for c in names_conversation_dynamics[1:] for m in names_measures]\n",
    "\n",
    "    # Compute the correlation matrix\n",
    "    correlation_matrix = df[conv_dyn_measures].corr()\n",
    "    \n",
    "    # Rename rows and columns to use nice readable names\n",
    "    if name_mapping is not None:\n",
    "        correlation_matrix.rename(columns=name_mapping, index=name_mapping, inplace=True)\n",
    "\n",
    "    # Generate the title of the correlation matrix\n",
    "    if setting == \"conv\":\n",
    "        title = \"Conversation Dynamics Measures - Conversation Setting\"\n",
    "\n",
    "    elif setting == \"coll\":\n",
    "        title = \"Conversation Dynamics Measures - Collaboration Setting\"\n",
    "\n",
    "    elif setting == \"both\":\n",
    "        title = \"Conversation Dynamics Measures - Both Settings\"\n",
    "\n",
    "    # Plot the correlation matrix\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=annotate, fmt=\".2f\", cmap=\"coolwarm\", square=True, cbar_kws={\"shrink\": .8})\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highly_correlated_pairs(correlation_matrix, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Get highly correlated pairs of variables from the correlation matrix.\n",
    "\n",
    "    Args:\n",
    "    - correlation_matrix (pd.DataFrame): The correlation matrix.\n",
    "    - threshold (float): The threshold for high correlation (default is 0.7).\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of tuples representing the highly correlated pairs.\n",
    "    \"\"\"\n",
    "    # Get the upper triangle of the correlation matrix\n",
    "    upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    # Find pairs with absolute correlation greater than the threshold\n",
    "    highly_correlated = [(col1, col2) for col1 in upper_triangle.columns for col2 in upper_triangle.index if abs(upper_triangle[col1][col2]) > threshold]\n",
    "\n",
    "    # Print the highly correlated pairs\n",
    "    print(\"Highly correlated pairs:\", (len(highly_correlated)))\n",
    "    for (p1, p2) in highly_correlated:\n",
    "        print(f\"{p1} and {p2}: {correlation_matrix.loc[p1, p2]:.2f}\")\n",
    "\n",
    "    return highly_correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vif(df, include_prefixes=None, include_setting=False, exclude_columns=None):\n",
    "    \"\"\"\n",
    "    Calculate VIF for selected columns in a dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input dataframe\n",
    "    - include_prefixes (tuple or list of str): Column name prefixes to include (e.g., (\"self_\", \"other_\"))\n",
    "    - include_setting (bool): Whether to include the 'setting' column in the analysis\n",
    "    - exclude_columns (list of str): Column names to exclude from the analysis\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    # Filter included columns (based on prefix)\n",
    "    if include_prefixes is not None:\n",
    "        included_cols = [col for col in df.columns if col.startswith(tuple(include_prefixes))]\n",
    "    else:\n",
    "        included_cols = list(df.columns)\n",
    "\n",
    "    # Include the 'setting' column if specified\n",
    "    if include_setting:\n",
    "        included_cols.append(\"setting\")\n",
    "    \n",
    "    # Remove excluded columns\n",
    "    if exclude_columns is not None:\n",
    "        predictor_vars = [col for col in included_cols if col not in exclude_columns]\n",
    "    else:\n",
    "        predictor_vars = included_cols\n",
    "\n",
    "    # Add constant\n",
    "    X = add_constant(df[predictor_vars])\n",
    "\n",
    "    # Calculate VIF\n",
    "    vif_data = pd.DataFrame({\n",
    "        \"Variable\": X.columns,\n",
    "        \"VIF\": [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    })\n",
    "\n",
    "    print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from technical names to nice readable names (for plotting)\n",
    "name_mapping = {\n",
    "    \"self_speaking_time\": \"Self speaking time\",\n",
    "    \"other_speaking_time\": \"Other speaking time\",\n",
    "    \"self_turn_lengths_median\": \"Self turn length (median)\",\n",
    "    \"self_turn_lengths_variability\": \"Self turn length (variability)\",\n",
    "    \"self_turn_lengths_adaptability\": \"Self turn length (adaptability)\",\n",
    "    \"self_turn_lengths_predictability\": \"Self turn length (predictability)\",\n",
    "    \"other_turn_lengths_median\": \"Other turn length (median)\",\n",
    "    \"other_turn_lengths_variability\": \"Other turn length (variability)\",\n",
    "    \"other_turn_lengths_adaptability\": \"Other turn length (adaptability)\",\n",
    "    \"other_turn_lengths_predictability\": \"Other turn length (predictability)\",\n",
    "    \"self_speaking_rate_median\": \"Self speech rate (median)\",\n",
    "    \"self_speaking_rate_variability\": \"Self speech rate (variability)\",\n",
    "    \"self_speaking_rate_adaptability\": \"Self speech rate (adaptability)\",\n",
    "    \"self_speaking_rate_predictability\": \"Self speech rate (predictability)\",\n",
    "    \"other_speaking_rate_median\": \"Other speech rate (median)\",\n",
    "    \"other_speaking_rate_variability\": \"Other speech rate (variability)\",\n",
    "    \"other_speaking_rate_adaptability\": \"Other speech rate (adaptability)\",\n",
    "    \"other_speaking_rate_predictability\": \"Other speech rate (predictability)\",\n",
    "    \"self_response_times_median\": \"Self response time (median)\",\n",
    "    \"self_response_times_variability\": \"Self response time (variability)\",\n",
    "    \"self_response_times_adaptability\": \"Self response time (adaptability)\",\n",
    "    \"self_response_times_predictability\": \"Self response time (predictability)\",\n",
    "    \"other_response_times_median\": \"Other response time (median)\",\n",
    "    \"other_response_times_variability\": \"Other response time (variability)\",\n",
    "    \"other_response_times_adaptability\": \"Other response time (adaptability)\",\n",
    "    \"other_response_times_predictability\": \"Other response time (predictability)\",\n",
    "    \"setting\": \"Setting\",\n",
    "\n",
    "    # Interaction terms\n",
    "    \"setting_x_self_speaking_time\": \"Setting × Self speaking time\",\n",
    "    \"setting_x_other_speaking_time\": \"Setting × Other speaking time\",\n",
    "    \"setting_x_self_turn_lengths_median\": \"Setting × Self turn length (median)\",\n",
    "    \"setting_x_self_turn_lengths_variability\": \"Setting × Self turn length (variability)\",\n",
    "    \"setting_x_self_turn_lengths_adaptability\": \"Setting × Self turn length (adaptability)\",\n",
    "    \"setting_x_self_turn_lengths_predictability\": \"Setting × Self turn length (predictability)\",\n",
    "    \"setting_x_other_turn_lengths_median\": \"Setting × Other turn length (median)\",\n",
    "    \"setting_x_other_turn_lengths_variability\": \"Setting × Other turn length (variability)\",\n",
    "    \"setting_x_other_turn_lengths_adaptability\": \"Setting × Other turn length (adaptability)\",\n",
    "    \"setting_x_other_turn_lengths_predictability\": \"Setting × Other turn length (predictability)\",\n",
    "    \"setting_x_self_speaking_rate_median\": \"Setting × Self speech rate (median)\",\n",
    "    \"setting_x_self_speaking_rate_variability\": \"Setting × Self speech rate (variability)\",\n",
    "    \"setting_x_self_speaking_rate_adaptability\": \"Setting × Self speech rate (adaptability)\",\n",
    "    \"setting_x_self_speaking_rate_predictability\": \"Setting × Self speech rate (predictability)\",\n",
    "    \"setting_x_other_speaking_rate_median\": \"Setting × Other speech rate (median)\",\n",
    "    \"setting_x_other_speaking_rate_variability\": \"Setting × Other speech rate (variability)\",\n",
    "    \"setting_x_other_speaking_rate_adaptability\": \"Setting × Other speech rate (adaptability)\",\n",
    "    \"setting_x_other_speaking_rate_predictability\": \"Setting × Other speech rate (predictability)\",\n",
    "    \"setting_x_self_response_times_median\": \"Setting × Self response time (median)\",\n",
    "    \"setting_x_self_response_times_variability\": \"Setting × Self response time (variability)\",\n",
    "    \"setting_x_self_response_times_adaptability\": \"Setting × Self response time (adaptability)\",\n",
    "    \"setting_x_self_response_times_predictability\": \"Setting × Self response time (predictability)\",\n",
    "    \"setting_x_other_response_times_median\": \"Setting × Other response time (median)\",\n",
    "    \"setting_x_other_response_times_variability\": \"Setting × Other response time (variability)\",\n",
    "    \"setting_x_other_response_times_adaptability\": \"Setting × Other response time (adaptability)\",\n",
    "    \"setting_x_other_response_times_predictability\": \"Setting × Other response time (predictability)\",\n",
    "\n",
    "    # Robustness check\n",
    "    \"self_age\": \"Self age\",\n",
    "    \"other_age\": \"Other age\",\n",
    "    \"self_sex\": \"Self sex\",\n",
    "    \"other_sex\": \"Other sex\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Setting (RQ1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measures of one participant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_self_conv = get_correlation_matrix(df_stnd_split_measures_conv, \"conv\", True, False, False, False, name_mapping)\n",
    "high_corr_pairs_self_conv = highly_correlated_pairs(correlation_matrix_self_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measures of both participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_both_conv = get_correlation_matrix(df_stnd_split_measures_conv, \"conv\", True, True, False, False, name_mapping)\n",
    "high_corr_pairs_both_conv = highly_correlated_pairs(correlation_matrix_both_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variation Inflation Factor (VIF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measures of both participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate VIF for self_ and other_ measures\n",
    "calculate_vif(df_stnd_split_measures_conv, include_prefixes=[\"self_\", \"other_\"], exclude_columns=[\"self_recording_file\", \"other_recording_file\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations between self_speaking_time/other_speaking_time and rapport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between rapport and self_speaking_time and other_speaking_time\n",
    "corr_rapport_self = df_stnd_split_measures_conv[\"self_speaking_time\"].corr(df_stnd_split_measures_conv[\"rapport\"])\n",
    "corr_rapport_other = df_stnd_split_measures_conv[\"other_speaking_time\"].corr(df_stnd_split_measures_conv[\"rapport\"])\n",
    "\n",
    "print(f\"Correlation between self_speaking_time and rapport: {corr_rapport_self:.2f}\")\n",
    "print(f\"Correlation between other_speaking_time and rapport: {corr_rapport_other:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF after excluding self_speaking_time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_vif(df_stnd_split_measures_conv, include_prefixes=[\"self_\", \"other_\"], exclude_columns=[\"self_recording_file\", \"other_recording_file\", \"self_speaking_time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative Link-Mixed Model (CLMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All conversation dynamics measures (except self speaking time)\n",
    "formula_full_other = (\n",
    "    'rapport ~ other_speaking_time + '\n",
    "    'self_turn_lengths_median + self_turn_lengths_variability + '\n",
    "    'self_turn_lengths_adaptability + self_turn_lengths_predictability + '\n",
    "    'other_turn_lengths_median + other_turn_lengths_variability + '\n",
    "    'other_turn_lengths_adaptability + other_turn_lengths_predictability + '\n",
    "    'self_speaking_rate_median + self_speaking_rate_variability + '\n",
    "    'self_speaking_rate_adaptability + self_speaking_rate_predictability + '\n",
    "    'other_speaking_rate_median + other_speaking_rate_variability + '\n",
    "    'other_speaking_rate_adaptability + other_speaking_rate_predictability + '\n",
    "    'self_response_times_median + self_response_times_variability + '\n",
    "    'self_response_times_adaptability + self_response_times_predictability + '\n",
    "    'other_response_times_median + other_response_times_variability + '\n",
    "    'other_response_times_adaptability + other_response_times_predictability + '\n",
    "    '(1 | dyadID) + (1 | selfPID)'\n",
    ")\n",
    "\n",
    "ro.globalenv['formula_full_other'] = formula_full_other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable conversion between Pandas and R data frames\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Load R's 'ordinal' package\n",
    "ordinal = importr(\"ordinal\")\n",
    "\n",
    "# Convert to R dataframe\n",
    "r_df_conv = pandas2ri.py2rpy(df_stnd_split_measures_conv)\n",
    "\n",
    "# Define the CLMM model in R\n",
    "ro.r.assign(\"r_df_conv\", r_df_conv)\n",
    "ro.r('''\n",
    "# install.packages(\"ordinal\") # Uncomment if you need to install the package\n",
    "library(ordinal)\n",
    "     \n",
    "r_df_conv$rapport <- as.ordered(r_df_conv$rapport)  # Ensure it's ordinal\n",
    "\n",
    "# Fit the model\n",
    "clmm_model_full_other <- clmm(as.formula(formula_full_other), data = r_df_conv)\n",
    "     \n",
    "# Save the model summary to a text file     \n",
    "sink(\"models/RQ1/no_weights/clmm_full_other.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_full_other))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "# Save the model to a file\n",
    "saveRDS(clmm_model_full_other, file = \"models/RQ1/comparison/clmm_full_other_unweighted.rds\")\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable conversion between Pandas and R data frames\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Load R's 'ordinal' package\n",
    "ordinal = importr(\"ordinal\")\n",
    "\n",
    "# Convert to R dataframe\n",
    "r_df_conv = pandas2ri.py2rpy(df_stnd_split_measures_conv)\n",
    "\n",
    "# Define the CLMM model in R\n",
    "ro.r.assign(\"r_df_conv\", r_df_conv)\n",
    "ro.r('''\n",
    "# install.packages(\"ordinal\") # Uncomment if you need to install the package\n",
    "library(ordinal)\n",
    "     \n",
    "r_df_conv$rapport <- as.ordered(r_df_conv$rapport)  # Ensure it's ordinal\n",
    "\n",
    "# Weights\n",
    "freqs <- table(r_df_conv$rapport)\n",
    "r_df_conv$weights <- 1 / sqrt(freqs[as.character(r_df_conv$rapport)]) # Square root of inverse frequency\n",
    "# r_df_conv$weights <- 1 / freqs[as.character(r_df_conv$rapport)] # Normalized inverse frequency\n",
    "r_df_conv$weights <- r_df_conv$weights * nrow(r_df_conv) / sum(r_df_conv$weights)\n",
    "     \n",
    "# Print the unique weight values sorted by frequency\n",
    "sorted_weights <- sort(table(r_df_conv$weights), decreasing = TRUE)\n",
    "cat(\"Weights (sorted by frequency):\\n\")\n",
    "print(sorted_weights)\n",
    "\n",
    "# Log transform (adding 1 to avoid log(0))\n",
    "raw_weights <- r_df_conv$weights\n",
    "log_weights <- log1p(raw_weights)\n",
    "r_df_conv$weights <- log_weights\n",
    "\n",
    "# Print the unique weight values sorted by frequency (after log transformation)\n",
    "sorted_weights <- sort(table(r_df_conv$weights), decreasing = TRUE)\n",
    "cat(\"Weights (sorted by frequency) after log transformation:\\n\")\n",
    "print(sorted_weights)\n",
    "     \n",
    "# Fit the model\n",
    "clmm_model_full_other <- clmm(as.formula(formula_full_other), data = r_df_conv, weights = weights)\n",
    "     \n",
    "# Save the model summary to a text file        \n",
    "sink(\"models/RQ1/weights/clmm_full_other.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_full_other))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "# Compare weighted and unweighted models\n",
    "unweighted_model <- readRDS(\"models/RQ1/comparison/clmm_full_other_unweighted.rds\")\n",
    "weighted_model <- clmm_model_full_other\n",
    "anova_results <- anova(unweighted_model, weighted_model)\n",
    "    \n",
    "# Save the comparison results to a text file\n",
    "sink(\"models/RQ1/comparison/clmm_full_other_comparison.txt\") # Redirect output to a file\n",
    "print(anova_results)\n",
    "sink() # Stop redirecting output\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Robustness Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include age and gender of both participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes on 'globalPID' and 'selfPID'\n",
    "df_robustness_conv = pd.merge(df_stnd_split_measures_conv, questionnaire_intake[[\"globalPID\", \"Age_part\", \"Sex_part\"]], left_on=\"selfPID\", right_on=\"globalPID\", how=\"left\")\n",
    "df_robustness_conv = df_robustness_conv.drop(columns=[\"globalPID\"])\n",
    "\n",
    "# Rename the columns\n",
    "df_robustness_conv = df_robustness_conv.rename(columns={'Age_part': 'self_age', 'Sex_part': 'self_sex'})\n",
    "\n",
    "# Merge the two dataframes on 'globalPID' and 'otherPID'\n",
    "df_robustness_conv = pd.merge(df_robustness_conv, questionnaire_intake[[\"globalPID\", \"Age_part\", \"Sex_part\"]], left_on=\"otherPID\", right_on=\"globalPID\", how=\"left\")\n",
    "df_robustness_conv = df_robustness_conv.drop(columns=[\"globalPID\"])\n",
    "\n",
    "# Rename the columns\n",
    "df_robustness_conv = df_robustness_conv.rename(columns={'Age_part': 'other_age', 'Sex_part': 'other_sex'})\n",
    "\n",
    "# Standardize the added columns\n",
    "df_robustness_conv[[\"self_age\", \"self_sex\", \"other_age\", \"other_sex\"]] = standardize(df_robustness_conv[[\"self_age\", \"self_sex\", \"other_age\", \"other_sex\"]])\n",
    "\n",
    "df_robustness_conv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variation Inflation Factor (VIF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measures of both participants (excluding self_speaking_time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate VIF for self_ and other_ measures (without categorical variables)\n",
    "calculate_vif(df_robustness_conv, include_prefixes=[\"self_\", \"other_\"], exclude_columns=[\"self_recording_file\", \"other_recording_file\", \"self_speaking_time\", \"self_sex\", \"other_sex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cumulative Link-Mixed Model (CLMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_full_other_robustness = formula_full_other + ' + self_age + other_age + self_sex + other_sex'\n",
    "\n",
    "ro.globalenv['formula_full_other_robustness'] = formula_full_other_robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable conversion between Pandas and R data frames\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Load R's 'ordinal' package\n",
    "ordinal = importr(\"ordinal\")\n",
    "\n",
    "# Convert to R dataframe\n",
    "r_df_robustness_conv = pandas2ri.py2rpy(df_robustness_conv)\n",
    "\n",
    "# Define the CLMM model in R\n",
    "ro.r.assign(\"r_df_robustness_conv\", r_df_robustness_conv)\n",
    "ro.r('''\n",
    "# install.packages(\"ordinal\") # Uncomment if you need to install the package\n",
    "library(ordinal)\n",
    "     \n",
    "r_df_robustness_conv$rapport <- as.ordered(r_df_robustness_conv$rapport)  # Ensure it's ordinal\n",
    "r_df_robustness_conv$self_sex <- as.factor(r_df_robustness_conv$self_sex) # Ensure it's categorical\n",
    "r_df_robustness_conv$other_sex <- as.factor(r_df_robustness_conv$other_sex) # Ensure it's categorical\n",
    "\n",
    "# Fit the model\n",
    "clmm_model_full_other <- clmm(as.formula(formula_full_other_robustness), data = r_df_robustness_conv)\n",
    "     \n",
    "# Save the model summary to a text file     \n",
    "sink(\"models/RQ1/robustness_no_weights/clmm_full_other.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_full_other))\n",
    "sink() # Stop redirecting output\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable conversion between Pandas and R data frames\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Load R's 'ordinal' package\n",
    "ordinal = importr(\"ordinal\")\n",
    "\n",
    "# Convert to R dataframe\n",
    "r_df_robustness_conv = pandas2ri.py2rpy(df_robustness_conv)\n",
    "\n",
    "# Define the CLMM model in R\n",
    "ro.r.assign(\"r_df_robustness_conv\", r_df_robustness_conv)\n",
    "ro.r('''\n",
    "# install.packages(\"ordinal\") # Uncomment if you need to install the package\n",
    "library(ordinal)\n",
    "     \n",
    "r_df_robustness_conv$rapport <- as.ordered(r_df_robustness_conv$rapport)  # Ensure it's ordinal\n",
    "r_df_robustness_conv$self_sex <- as.factor(r_df_robustness_conv$self_sex) # Ensure it's categorical\n",
    "r_df_robustness_conv$other_sex <- as.factor(r_df_robustness_conv$other_sex) # Ensure it's categorical\n",
    "\n",
    "# Weights\n",
    "freqs <- table(r_df_robustness_conv$rapport)\n",
    "r_df_robustness_conv$weights <- 1 / sqrt(freqs[as.character(r_df_robustness_conv$rapport)]) # Square root of inverse frequency\n",
    "# r_df_robustness_conv$weights <- 1 / freqs[as.character(r_df_robustness_conv$rapport)] # Normalized inverse frequency\n",
    "r_df_robustness_conv$weights <- r_df_robustness_conv$weights * nrow(r_df_robustness_conv) / sum(r_df_robustness_conv$weights)\n",
    "     \n",
    "# Print the unique weight values sorted by frequency\n",
    "sorted_weights <- sort(table(r_df_robustness_conv$weights), decreasing = TRUE)\n",
    "cat(\"Weights (sorted by frequency):\\n\")\n",
    "print(sorted_weights)\n",
    "\n",
    "# Log transform (adding 1 to avoid log(0))\n",
    "raw_weights <- r_df_robustness_conv$weights\n",
    "log_weights <- log1p(raw_weights)\n",
    "r_df_robustness_conv$weights <- log_weights\n",
    "\n",
    "# Print the unique weight values sorted by frequency (after log transformation)\n",
    "sorted_weights <- sort(table(r_df_robustness_conv$weights), decreasing = TRUE)\n",
    "cat(\"Weights (sorted by frequency) after log transformation:\\n\")\n",
    "print(sorted_weights)\n",
    "\n",
    "# Fit the model\n",
    "clmm_model_full_other <- clmm(as.formula(formula_full_other_robustness), data = r_df_robustness_conv, weights = weights)   \n",
    "     \n",
    "# Save the model summary to a text file     \n",
    "sink(\"models/RQ1/robustness_weights/clmm_full_other.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_full_other))\n",
    "sink() # Stop redirecting output\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both Settings (RQ2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measures of one participant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_self_combined = get_correlation_matrix(df_stnd_split_measures_combined, \"both\", True, False, False, False, name_mapping)\n",
    "high_corr_pairs_self_combined = highly_correlated_pairs(correlation_matrix_self_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measures of both participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_both_combined = get_correlation_matrix(df_stnd_split_measures_combined, \"both\", True, True, False, False, name_mapping)\n",
    "high_corr_pairs_both_both = highly_correlated_pairs(correlation_matrix_both_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main measures and interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_both_combined_interact = get_correlation_matrix(df_stnd_split_measures_combined, \"both\", True, True, True, False, name_mapping)\n",
    "high_corr_pairs_both_both = highly_correlated_pairs(correlation_matrix_both_combined_interact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variation Inflation Factor (VIF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measures of both participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_vif(df_stnd_split_measures_combined, include_prefixes=[\"self_\", \"other_\"], include_setting=True, exclude_columns=[\"self_recording_file\", \"other_recording_file\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main measures and interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_vif(df_stnd_split_measures_combined, include_prefixes=[\"self_\", \"other_\", \"setting\"], exclude_columns=[\"self_recording_file\", \"other_recording_file\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations between self_speaking_time/other_speaking_time and rapport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between rapport and self_speaking_time and other_speaking_time\n",
    "corr_rapport_self = df_stnd_split_measures_combined[\"self_speaking_time\"].corr(df_stnd_split_measures_combined[\"rapport\"])\n",
    "corr_rapport_self_int = df_stnd_split_measures_combined[\"setting_x_self_speaking_time\"].corr(df_stnd_split_measures_combined[\"rapport\"])\n",
    "corr_rapport_other = df_stnd_split_measures_combined[\"other_speaking_time\"].corr(df_stnd_split_measures_combined[\"rapport\"])\n",
    "corr_rapport_other_int = df_stnd_split_measures_combined[\"setting_x_other_speaking_time\"].corr(df_stnd_split_measures_combined[\"rapport\"])\n",
    "\n",
    "print(f\"Correlation between self_speaking_time and rapport: {corr_rapport_self:.2f}\")\n",
    "print(f\"Correlation between setting_x_self_speaking_time and rapport: {corr_rapport_self_int:.2f}\")\n",
    "print(f\"Correlation between other_speaking_time and rapport: {corr_rapport_other:.2f}\")\n",
    "print(f\"Correlation between setting_x_other_speaking_time and rapport: {corr_rapport_other_int:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF after excluding self_speaking_time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_vif(df_stnd_split_measures_combined, include_prefixes=[\"self_\", \"other_\", \"setting\"], exclude_columns=[\"self_recording_file\", \"other_recording_file\", \"self_speaking_time\", \"setting_x_self_speaking_time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modular Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_vif(df_stnd_split_measures_combined, include_prefixes=[\"other_speaking_time\", \"setting_x_other_speaking_time\"], include_setting=True, exclude_columns=[\"self_recording_file\", \"other_recording_file\"])\n",
    "calculate_vif(df_stnd_split_measures_combined, include_prefixes=[\"self_turn_lengths\", \"other_turn_lengths\", \"setting_x_self_turn_lengths\", \"setting_x_other_turn_lengths\"], include_setting=True, exclude_columns=[\"self_recording_file\", \"other_recording_file\"])\n",
    "calculate_vif(df_stnd_split_measures_combined, include_prefixes=[\"self_speaking_rate\", \"other_speaking_rate\", \"setting_x_self_speaking_rate\", \"setting_x_other_speaking_rate\"], include_setting=True, exclude_columns=[\"self_recording_file\", \"other_recording_file\"])\n",
    "calculate_vif(df_stnd_split_measures_combined, include_prefixes=[\"self_response_times\", \"other_response_times\", \"setting_x_self_response_times\", \"setting_x_other_response_times\"], include_setting=True, exclude_columns=[\"self_recording_file\", \"other_recording_file\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative Link-Mixed Model (CLMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modular models\n",
    "formula_speaking_time_interaction = (\n",
    "    'rapport ~ other_speaking_time + setting_x_other_speaking_time + '\n",
    "    'setting + (1 | dyadID) + (1 | selfPID)'\n",
    ")\n",
    "\n",
    "ro.globalenv['formula_speaking_time_interaction'] = formula_speaking_time_interaction\n",
    "\n",
    "formula_turn_lengths_interaction = (\n",
    "    'rapport ~ self_turn_lengths_median + setting_x_self_turn_lengths_median + '\n",
    "    'self_turn_lengths_variability + setting_x_self_turn_lengths_variability + '\n",
    "    'self_turn_lengths_adaptability + setting_x_self_turn_lengths_adaptability + '\n",
    "    'self_turn_lengths_predictability + setting_x_self_turn_lengths_predictability + '\n",
    "    'other_turn_lengths_median + setting_x_other_turn_lengths_median + '\n",
    "    'other_turn_lengths_variability + setting_x_other_turn_lengths_variability + '\n",
    "    'other_turn_lengths_adaptability + setting_x_other_turn_lengths_adaptability + '\n",
    "    'other_turn_lengths_predictability + setting_x_other_turn_lengths_predictability + '\n",
    "    'setting + (1 | dyadID) + (1 | selfPID)'\n",
    ")\n",
    "\n",
    "ro.globalenv['formula_turn_lengths_interaction'] = formula_turn_lengths_interaction\n",
    "\n",
    "formula_speaking_rate_interaction = (\n",
    "    'rapport ~ self_speaking_rate_median + setting_x_self_speaking_rate_median + '\n",
    "    'self_speaking_rate_variability + setting_x_self_speaking_rate_variability + '\n",
    "    'self_speaking_rate_adaptability + setting_x_self_speaking_rate_adaptability + '\n",
    "    'self_speaking_rate_predictability + setting_x_self_speaking_rate_predictability + '\n",
    "    'other_speaking_rate_median + setting_x_other_speaking_rate_median + '\n",
    "    'other_speaking_rate_variability + setting_x_other_speaking_rate_variability + '\n",
    "    'other_speaking_rate_adaptability + setting_x_other_speaking_rate_adaptability + '\n",
    "    'other_speaking_rate_predictability + setting_x_other_speaking_rate_predictability + '\n",
    "    'setting + (1 | dyadID) + (1 | selfPID)'\n",
    ")\n",
    "\n",
    "ro.globalenv['formula_speaking_rate_interaction'] = formula_speaking_rate_interaction\n",
    "\n",
    "formula_response_times_interaction = (\n",
    "    'rapport ~ self_response_times_median + setting_x_self_response_times_median + '\n",
    "    'self_response_times_variability + setting_x_self_response_times_variability + '\n",
    "    'self_response_times_adaptability + setting_x_self_response_times_adaptability + '\n",
    "    'self_response_times_predictability + setting_x_self_response_times_predictability + '\n",
    "    'other_response_times_median + setting_x_other_response_times_median + '\n",
    "    'other_response_times_variability + setting_x_other_response_times_variability + '\n",
    "    'other_response_times_adaptability + setting_x_other_response_times_adaptability + '\n",
    "    'other_response_times_predictability + setting_x_other_response_times_predictability + '\n",
    "    'setting + (1 | dyadID) + (1 | selfPID)'\n",
    ")\n",
    "\n",
    "ro.globalenv['formula_response_times_interaction'] = formula_response_times_interaction\n",
    "\n",
    "# All conversation dynamics measures (except self speaking time)\n",
    "formula_full_other_interaction = (\n",
    "    'rapport ~ other_speaking_time + setting_x_other_speaking_time + '\n",
    "    'self_turn_lengths_median + setting_x_self_turn_lengths_median + '\n",
    "    'self_turn_lengths_variability + setting_x_self_turn_lengths_variability + '\n",
    "    'self_turn_lengths_adaptability + setting_x_self_turn_lengths_adaptability + '\n",
    "    'self_turn_lengths_predictability + setting_x_self_turn_lengths_predictability + '\n",
    "    'other_turn_lengths_median + setting_x_other_turn_lengths_median + '\n",
    "    'other_turn_lengths_variability + setting_x_other_turn_lengths_variability + '\n",
    "    'other_turn_lengths_adaptability + setting_x_other_turn_lengths_adaptability + '\n",
    "    'other_turn_lengths_predictability + setting_x_other_turn_lengths_predictability + '\n",
    "    'self_speaking_rate_median + setting_x_self_speaking_rate_median + '\n",
    "    'self_speaking_rate_variability + setting_x_self_speaking_rate_variability + '\n",
    "    'self_speaking_rate_adaptability + setting_x_self_speaking_rate_adaptability + '\n",
    "    'self_speaking_rate_predictability + setting_x_self_speaking_rate_predictability + '\n",
    "    'other_speaking_rate_median + setting_x_other_speaking_rate_median + '\n",
    "    'other_speaking_rate_variability + setting_x_other_speaking_rate_variability + '\n",
    "    'other_speaking_rate_adaptability + setting_x_other_speaking_rate_adaptability + '\n",
    "    'other_speaking_rate_predictability + setting_x_other_speaking_rate_predictability + '\n",
    "    'self_response_times_median + setting_x_self_response_times_median + '\n",
    "    'self_response_times_variability + setting_x_self_response_times_variability + '\n",
    "    'self_response_times_adaptability + setting_x_self_response_times_adaptability + '\n",
    "    'self_response_times_predictability + setting_x_self_response_times_predictability + '\n",
    "    'other_response_times_median + setting_x_other_response_times_median + '\n",
    "    'other_response_times_variability + setting_x_other_response_times_variability + '\n",
    "    'other_response_times_adaptability + setting_x_other_response_times_adaptability + '\n",
    "    'other_response_times_predictability + setting_x_other_response_times_predictability + '\n",
    "    'setting + (1 | dyadID) + (1 | selfPID)'    \n",
    ")\n",
    "\n",
    "ro.globalenv['formula_full_other_interaction'] = formula_full_other_interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable conversion between Pandas and R data frames\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Load R's 'ordinal' package\n",
    "ordinal = importr(\"ordinal\")\n",
    "\n",
    "# Convert to R dataframe\n",
    "r_df_combined = pandas2ri.py2rpy(df_stnd_split_measures_combined)\n",
    "\n",
    "# Define the CLMM model in R\n",
    "ro.r.assign(\"r_df_combined\", r_df_combined)\n",
    "ro.r('''\n",
    "# install.packages(\"ordinal\") # Uncomment if you need to install the package\n",
    "library(ordinal)\n",
    "     \n",
    "r_df_combined$rapport <- as.ordered(r_df_combined$rapport)  # Ensure it's ordinal\n",
    "\n",
    "# Fit the models\n",
    "clmm_model_speaking_time <- clmm(as.formula(formula_speaking_time_interaction), data = r_df_combined)\n",
    "clmm_model_turn_lengths <- clmm(as.formula(formula_turn_lengths_interaction), data = r_df_combined)\n",
    "clmm_model_speaking_rate <- clmm(as.formula(formula_speaking_rate_interaction), data = r_df_combined)\n",
    "clmm_model_response_times <- clmm(as.formula(formula_response_times_interaction), data = r_df_combined)\n",
    "clmm_model_full_other <- clmm(as.formula(formula_full_other_interaction), data = r_df_combined)\n",
    "     \n",
    "# Save the model summaries to text files\n",
    "sink(\"models/RQ2/no_weights/clmm_speaking_time.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_speaking_time))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "sink(\"models/RQ2/no_weights/clmm_turn_lengths.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_turn_lengths))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "sink(\"models/RQ2/no_weights/clmm_speaking_rate.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_speaking_rate))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "sink(\"models/RQ2/no_weights/clmm_response_times.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_response_times))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "sink(\"models/RQ2/no_weights/clmm_full_other.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_full_other))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "# Save the full_other model to a file\n",
    "saveRDS(clmm_model_full_other, file = \"models/RQ2/comparison/clmm_full_other_unweighted.rds\")\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable conversion between Pandas and R data frames\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Load R's 'ordinal' package\n",
    "ordinal = importr(\"ordinal\")\n",
    "\n",
    "# Convert to R dataframe\n",
    "r_df_combined = pandas2ri.py2rpy(df_stnd_split_measures_combined)\n",
    "\n",
    "# Define the CLMM model in R\n",
    "ro.r.assign(\"r_df_combined\", r_df_combined)\n",
    "ro.r('''\n",
    "# install.packages(\"ordinal\") # Uncomment if you need to install the package\n",
    "library(ordinal)\n",
    "     \n",
    "r_df_combined$rapport <- as.ordered(r_df_combined$rapport)  # Ensure it's ordinal\n",
    "     \n",
    "# Weights\n",
    "freqs <- table(r_df_combined$rapport)\n",
    "r_df_combined$weights <- 1 / sqrt(freqs[as.character(r_df_combined$rapport)]) # Square root of inverse frequency\n",
    "# r_df_combined$weights <- 1 / freqs[as.character(r_df_combined$rapport)] # Normalized inverse frequency\n",
    "r_df_combined$weights <- r_df_combined$weights * nrow(r_df_combined) / sum(r_df_combined$weights)\n",
    "     \n",
    "# Print the unique weight values sorted by frequency\n",
    "sorted_weights <- sort(table(r_df_combined$weights), decreasing = TRUE)\n",
    "cat(\"Weights (sorted by frequency):\\n\")\n",
    "print(sorted_weights)\n",
    "\n",
    "# Log transform (adding 1 to avoid log(0))\n",
    "raw_weights <- r_df_combined$weights\n",
    "log_weights <- log1p(raw_weights)\n",
    "r_df_combined$weights <- log_weights\n",
    "\n",
    "# Print the unique weight values sorted by frequency (after log transformation)\n",
    "sorted_weights <- sort(table(r_df_combined$weights), decreasing = TRUE)\n",
    "cat(\"Weights (sorted by frequency) after log transformation:\\n\")\n",
    "print(sorted_weights)\n",
    "\n",
    "# Fit the models\n",
    "clmm_model_speaking_time <- clmm(as.formula(formula_speaking_time_interaction), data = r_df_combined, weights = weights)\n",
    "clmm_model_turn_lengths <- clmm(as.formula(formula_turn_lengths_interaction), data = r_df_combined, weights = weights)\n",
    "clmm_model_speaking_rate <- clmm(as.formula(formula_speaking_rate_interaction), data = r_df_combined, weights = weights)\n",
    "clmm_model_response_times <- clmm(as.formula(formula_response_times_interaction), data = r_df_combined, weights = weights)\n",
    "clmm_model_full_other <- clmm(as.formula(formula_full_other_interaction), data = r_df_combined, weights = weights)\n",
    "     \n",
    "# Save the model summaries to text files\n",
    "sink(\"models/RQ2/weights/clmm_speaking_time.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_speaking_time))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "sink(\"models/RQ2/weights/clmm_turn_lengths.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_turn_lengths))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "sink(\"models/RQ2/weights/clmm_speaking_rate.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_speaking_rate))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "sink(\"models/RQ2/weights/clmm_response_times.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_response_times))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "sink(\"models/RQ2/weights/clmm_full_other.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_full_other))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "# Compare weighted and unweighted models\n",
    "unweighted_model <- readRDS(\"models/RQ2/comparison/clmm_full_other_unweighted.rds\")\n",
    "weighted_model <- clmm_model_full_other\n",
    "anova_results <- anova(unweighted_model, weighted_model)\n",
    "     \n",
    "# Save the comparison results to a text file\n",
    "sink(\"models/RQ2/comparison/clmm_full_other_comparison.txt\") # Redirect output to a file\n",
    "print(anova_results)\n",
    "sink() # Stop redirecting output\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Robustness Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include age and gender of both participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes on 'globalPID' and 'selfPID'\n",
    "df_robustness_combined = pd.merge(df_stnd_split_measures_combined, questionnaire_intake[[\"globalPID\", \"Age_part\", \"Sex_part\"]], left_on=\"selfPID\", right_on=\"globalPID\", how=\"left\")\n",
    "df_robustness_combined = df_robustness_combined.drop(columns=[\"globalPID\"])\n",
    "\n",
    "# Rename the columns\n",
    "df_robustness_combined = df_robustness_combined.rename(columns={'Age_part': 'self_age', 'Sex_part': 'self_sex'})\n",
    "\n",
    "# Merge the two dataframes on 'globalPID' and 'otherPID'\n",
    "df_robustness_combined = pd.merge(df_robustness_combined, questionnaire_intake[[\"globalPID\", \"Age_part\", \"Sex_part\"]], left_on=\"otherPID\", right_on=\"globalPID\", how=\"left\")\n",
    "df_robustness_combined = df_robustness_combined.drop(columns=[\"globalPID\"])\n",
    "\n",
    "# Rename the columns\n",
    "df_robustness_combined = df_robustness_combined.rename(columns={'Age_part': 'other_age', 'Sex_part': 'other_sex'})\n",
    "\n",
    "# Standardize the added columns\n",
    "df_robustness_combined[[\"self_age\", \"self_sex\", \"other_age\", \"other_sex\"]] = standardize(df_robustness_combined[[\"self_age\", \"self_sex\", \"other_age\", \"other_sex\"]])\n",
    "\n",
    "df_robustness_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variation Inflation Factor (VIF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measures of both participants (excluding self_speaking_time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate VIF for self_ and other_ measures (without categorical variables)\n",
    "calculate_vif(df_robustness_combined, include_prefixes=[\"self_\", \"other_\"], include_setting=True, exclude_columns=[\"self_recording_file\", \"other_recording_file\", \"self_speaking_time\", \"self_sex\", \"other_sex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main measures and interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_vif(df_robustness_combined, include_prefixes=[\"self_\", \"other_\", \"setting\"], exclude_columns=[\"self_recording_file\", \"other_recording_file\", \"self_speaking_time\", \"setting_x_self_speaking_time\", \"self_sex\", \"other_sex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modular models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_vif(df_robustness_combined, include_prefixes=[\"other_speaking_time\", \"setting_x_other_speaking_time\", \"self_age\", \"other_age\"], include_setting=True, exclude_columns=[\"self_recording_file\", \"other_recording_file\", \"self_sex\", \"other_sex\"])\n",
    "calculate_vif(df_robustness_combined, include_prefixes=[\"self_turn_lengths\", \"other_turn_lengths\", \"setting_x_self_turn_lengths\", \"setting_x_other_turn_lengths\", \"self_age\", \"other_age\"], include_setting=True, exclude_columns=[\"self_recording_file\", \"other_recording_file\", \"self_sex\", \"other_sex\"])\n",
    "calculate_vif(df_robustness_combined, include_prefixes=[\"self_speaking_rate\", \"other_speaking_rate\", \"setting_x_self_speaking_rate\", \"setting_x_other_speaking_rate\", \"self_age\", \"other_age\"], include_setting=True, exclude_columns=[\"self_recording_file\", \"other_recording_file\", \"self_sex\", \"other_sex\"])\n",
    "calculate_vif(df_robustness_combined, include_prefixes=[\"self_response_times\", \"other_response_times\", \"setting_x_self_response_times\", \"setting_x_other_response_times\", \"self_age\", \"other_age\"], include_setting=True, exclude_columns=[\"self_recording_file\", \"other_recording_file\", \"self_sex\", \"other_sex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cumulative Link-Mixed Model (CLMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_speaking_time_interaction_robustness = formula_speaking_time_interaction + ' + self_age + other_age + self_sex + other_sex'\n",
    "ro.globalenv['formula_speaking_time_interaction_robustness'] = formula_speaking_time_interaction_robustness\n",
    "\n",
    "formula_turn_lengths_interaction_robustness = formula_turn_lengths_interaction + ' + self_age + other_age + self_sex + other_sex'\n",
    "ro.globalenv['formula_turn_lengths_interaction_robustness'] = formula_turn_lengths_interaction_robustness\n",
    "\n",
    "formula_speaking_rate_interaction_robustness = formula_speaking_rate_interaction + ' + self_age + other_age + self_sex + other_sex'\n",
    "ro.globalenv['formula_speaking_rate_interaction_robustness'] = formula_speaking_rate_interaction_robustness\n",
    "\n",
    "formula_response_times_interaction_robustness = formula_response_times_interaction + ' + self_age + other_age + self_sex + other_sex'\n",
    "ro.globalenv['formula_response_times_interaction_robustness'] = formula_response_times_interaction_robustness\n",
    "\n",
    "formula_full_other_interaction_robustness = formula_full_other_interaction + ' + self_age + other_age + self_sex + other_sex'\n",
    "ro.globalenv['formula_full_other_interaction_robustness'] = formula_full_other_interaction_robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable conversion between Pandas and R data frames\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Load R's 'ordinal' package\n",
    "ordinal = importr(\"ordinal\")\n",
    "\n",
    "# Convert to R dataframe\n",
    "r_df_robustness_combined = pandas2ri.py2rpy(df_robustness_combined)\n",
    "\n",
    "# Define the CLMM model in R\n",
    "ro.r.assign(\"df_robustness_combined\", df_robustness_combined)\n",
    "ro.r('''\n",
    "# install.packages(\"ordinal\") # Uncomment if you need to install the package\n",
    "library(ordinal)\n",
    "     \n",
    "df_robustness_combined$rapport <- as.ordered(df_robustness_combined$rapport)  # Ensure it's ordinal\n",
    "df_robustness_combined$self_sex <- as.factor(df_robustness_combined$self_sex) # Ensure it's categorical\n",
    "df_robustness_combined$other_sex <- as.factor(df_robustness_combined$other_sex) # Ensure it's categorical\n",
    "\n",
    "# Fit the models\n",
    "clmm_model_speaking_time <- clmm(as.formula(formula_speaking_time_interaction_robustness), data = df_robustness_combined)\n",
    "clmm_model_turn_lengths <- clmm(as.formula(formula_turn_lengths_interaction_robustness), data = df_robustness_combined)\n",
    "clmm_model_speaking_rate <- clmm(as.formula(formula_speaking_rate_interaction_robustness), data = df_robustness_combined)\n",
    "clmm_model_response_times <- clmm(as.formula(formula_response_times_interaction_robustness), data = df_robustness_combined)\n",
    "clmm_model_full_other <- clmm(as.formula(formula_full_other_interaction_robustness), data = df_robustness_combined)\n",
    "     \n",
    "# Save the model summaries to text files\n",
    "sink(\"models/RQ2/robustness_no_weights/clmm_speaking_time.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_speaking_time))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "sink(\"models/RQ2/robustness_no_weights/clmm_turn_lengths.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_turn_lengths))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "sink(\"models/RQ2/robustness_no_weights/clmm_speaking_rate.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_speaking_rate))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "sink(\"models/RQ2/robustness_no_weights/clmm_response_times.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_response_times))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "sink(\"models/RQ2/robustness_no_weights/clmm_full_other.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_full_other))\n",
    "sink() # Stop redirecting output\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable conversion between Pandas and R data frames\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Load R's 'ordinal' package\n",
    "ordinal = importr(\"ordinal\")\n",
    "\n",
    "# Convert to R dataframe\n",
    "r_df_robustness_combined = pandas2ri.py2rpy(df_robustness_combined)\n",
    "\n",
    "# Define the CLMM model in R\n",
    "ro.r.assign(\"r_df_robustness_combined\", r_df_robustness_combined)\n",
    "ro.r('''\n",
    "# install.packages(\"ordinal\") # Uncomment if you need to install the package\n",
    "library(ordinal)\n",
    "     \n",
    "r_df_robustness_combined$rapport <- as.ordered(r_df_robustness_combined$rapport)  # Ensure it's ordinal\n",
    "r_df_robustness_combined$self_sex <- as.factor(r_df_robustness_combined$self_sex) # Ensure it's categorical\n",
    "r_df_robustness_combined$other_sex <- as.factor(r_df_robustness_combined$other_sex) # Ensure it's categorical\n",
    "\n",
    "# Weights\n",
    "freqs <- table(r_df_robustness_combined$rapport)\n",
    "r_df_robustness_combined$weights <- 1 / sqrt(freqs[as.character(r_df_robustness_combined$rapport)]) # Square root of inverse frequency\n",
    "# r_df_robustness_combined$weights <- 1 / freqs[as.character(r_df_robustness_combined$rapport)] # Normalized inverse frequency\n",
    "r_df_robustness_combined$weights <- r_df_robustness_combined$weights * nrow(r_df_robustness_combined) / sum(r_df_robustness_combined$weights)\n",
    "     \n",
    "# Print the unique weight values sorted by frequency\n",
    "sorted_weights <- sort(table(r_df_robustness_combined$weights), decreasing = TRUE)\n",
    "cat(\"Weights (sorted by frequency):\\n\")\n",
    "print(sorted_weights)\n",
    "\n",
    "# Log transform (adding 1 to avoid log(0))\n",
    "raw_weights <- r_df_robustness_combined$weights\n",
    "log_weights <- log1p(raw_weights)\n",
    "r_df_robustness_combined$weights <- log_weights\n",
    "\n",
    "# Print the unique weight values sorted by frequency (after log transformation)\n",
    "sorted_weights <- sort(table(r_df_robustness_combined$weights), decreasing = TRUE)\n",
    "cat(\"Weights (sorted by frequency) after log transformation:\\n\")\n",
    "print(sorted_weights)\n",
    "\n",
    "# Fit the models\n",
    "clmm_model_speaking_time <- clmm(as.formula(formula_speaking_time_interaction_robustness), data = r_df_robustness_combined, weights = weights)\n",
    "clmm_model_turn_lengths <- clmm(as.formula(formula_turn_lengths_interaction_robustness), data = r_df_robustness_combined, weights = weights)\n",
    "clmm_model_speaking_rate <- clmm(as.formula(formula_speaking_rate_interaction_robustness), data = r_df_robustness_combined, weights = weights)\n",
    "clmm_model_response_times <- clmm(as.formula(formula_response_times_interaction_robustness), data = r_df_robustness_combined, weights = weights)\n",
    "clmm_model_full_other <- clmm(as.formula(formula_full_other_interaction_robustness), data = r_df_robustness_combined, weights = weights)\n",
    "     \n",
    "# Save the model summaries to text files\n",
    "sink(\"models/RQ2/robustness_weights/clmm_speaking_time.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_speaking_time))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "sink(\"models/RQ2/robustness_weights/clmm_turn_lengths.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_turn_lengths))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "sink(\"models/RQ2/robustness_weights/clmm_speaking_rate.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_speaking_rate))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "sink(\"models/RQ2/robustness_weights/clmm_response_times.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_response_times))\n",
    "sink() # Stop redirecting output\n",
    "     \n",
    "sink(\"models/RQ2/robustness_weights/clmm_full_other.txt\") # Redirect output to a file\n",
    "print(summary(clmm_model_full_other))\n",
    "sink() # Stop redirecting output\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
